{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b071af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import exists\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df698969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\narr = np.array([[0, 1, 0], [1, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0]], dtype='float')\\nn = 3\\nk = 3\\narr = np.copy(add_features(arr, n, k))\\nprint(arr)\\n#print(np.mean(arr, axis=0))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features(arr1, n, k):\n",
    "    for i in range(n, len(arr1)):\n",
    "        new_point = np.zeros(3)\n",
    "        for j in range(i - k, i):\n",
    "            #Points towards the beginning have more contribution than the points towards the end\n",
    "            new_point += (((i-j)/k)*arr1[j])\n",
    "        new_point /= k\n",
    "        arr1[i] = new_point\n",
    "        k += 1\n",
    "    return arr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbef145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_SD(data):\n",
    "    mean = np.mean(data, axis=(0,1))\n",
    "    sd = np.std(data, axis=(0,1))\n",
    "    print(mean)\n",
    "    print(sd)\n",
    "    return (data-mean)/sd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f84dfa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "[[-7.673420e-01  4.330513e+00  7.996035e+00]\n",
      " [-8.260000e-01  4.371214e+00  7.986458e+00]\n",
      " [-8.194150e-01  4.401740e+00  8.008605e+00]\n",
      " [-8.092400e-01  4.446631e+00  8.027160e+00]\n",
      " [-7.984660e-01  4.450222e+00  8.033744e+00]\n",
      " [-7.625530e-01  4.480150e+00  8.039729e+00]\n",
      " [-7.254430e-01  4.459201e+00  8.024766e+00]\n",
      " [-6.673840e-01  4.477157e+00  8.056489e+00]\n",
      " [-6.536170e-01  4.520253e+00  8.105570e+00]\n",
      " [-6.943180e-01  4.498705e+00  8.123527e+00]\n",
      " [-7.398080e-01  4.529829e+00  8.100183e+00]\n",
      " [-7.697360e-01  4.529829e+00  8.046912e+00]\n",
      " [-7.793130e-01  4.546589e+00  8.055291e+00]\n",
      " [-7.583630e-01  4.543596e+00  8.072051e+00]\n",
      " [-6.542160e-01  4.519654e+00  8.156446e+00]\n",
      " [-6.177040e-01  4.499902e+00  8.207323e+00]\n",
      " [-5.985500e-01  4.460398e+00  8.176199e+00]\n",
      " [-5.907690e-01  4.423886e+00  8.143278e+00]\n",
      " [-5.590460e-01  4.370615e+00  8.240244e+00]\n",
      " [-5.045780e-01  4.404134e+00  8.529344e+00]\n",
      " [-6.703770e-01  4.428076e+00  7.665635e+00]\n",
      " [-8.098390e-01  4.653729e+00  6.799533e+00]\n",
      " [-6.757630e-01  4.598663e+00  6.754043e+00]\n",
      " [-3.836710e-01  4.438251e+00  7.585430e+00]\n",
      " [-4.285620e-01  4.324527e+00  8.720282e+00]\n",
      " [-7.691370e-01  4.083311e+00  9.515755e+00]\n",
      " [-8.816650e-01  4.099472e+00  9.699510e+00]\n",
      " [-8.313870e-01  4.290410e+00  9.197326e+00]\n",
      " [-6.476320e-01  4.555567e+00  8.496424e+00]\n",
      " [-3.501520e-01  4.833893e+00  7.963713e+00]\n",
      " [-3.351880e-01  4.887164e+00  8.100183e+00]\n",
      " [-6.655880e-01  4.747103e+00  8.450335e+00]\n",
      " [-7.194580e-01  4.721366e+00  8.674192e+00]\n",
      " [-6.314710e-01  4.751293e+00  8.674192e+00]\n",
      " [-4.770450e-01  4.799776e+00  8.467693e+00]\n",
      " [-3.681090e-01  4.822521e+00  8.257602e+00]\n",
      " [-2.861070e-01  4.784812e+00  8.244433e+00]\n",
      " [-2.154780e-01  4.702811e+00  8.465898e+00]\n",
      " [-1.741780e-01  4.540005e+00  8.757990e+00]\n",
      " [-1.610100e-01  4.377199e+00  9.040505e+00]\n",
      " [-1.502360e-01  4.187459e+00  9.102157e+00]\n",
      " [-7.062900e-02  4.009689e+00  9.033323e+00]\n",
      " [ 4.668700e-02  3.877410e+00  8.933964e+00]\n",
      " [ 1.113300e-01  3.767276e+00  8.841787e+00]\n",
      " [ 1.274910e-01  3.726575e+00  8.722675e+00]\n",
      " [ 1.472430e-01  3.742736e+00  8.605958e+00]\n",
      " [ 1.610100e-01  3.796605e+00  8.428188e+00]\n",
      " [ 2.352300e-01  3.932476e+00  7.979276e+00]\n",
      " [ 2.807200e-01  3.943250e+00  7.818265e+00]\n",
      " [ 3.238160e-01  3.942652e+00  7.767987e+00]\n",
      " [ 3.363850e-01  3.908534e+00  7.821258e+00]\n",
      " [ 2.424130e-01  3.838504e+00  7.920618e+00]\n",
      " [ 1.849520e-01  3.792415e+00  8.013393e+00]\n",
      " [ 7.242500e-02  3.773262e+00  8.049905e+00]\n",
      " [ 6.584000e-03  3.794810e+00  8.061875e+00]\n",
      " [ 2.394200e-02  3.797802e+00  8.089409e+00]\n",
      " [ 4.608800e-02  3.858256e+00  8.063671e+00]\n",
      " [ 7.481900e-02  3.886388e+00  8.048708e+00]\n",
      " [ 9.157800e-02  3.910928e+00  8.055890e+00]\n",
      " [ 1.155200e-01  3.962404e+00  8.032547e+00]\n",
      " [ 1.801640e-01  4.019266e+00  8.028357e+00]\n",
      " [ 2.466030e-01  4.046800e+00  8.036138e+00]\n",
      " [ 2.561800e-01  4.048595e+00  8.037933e+00]\n",
      " [ 2.292450e-01  4.086902e+00  8.160637e+00]\n",
      " [ 2.148800e-01  4.072537e+00  8.254609e+00]\n",
      " [ 1.909380e-01  4.091691e+00  8.274361e+00]\n",
      " [ 1.280900e-01  4.121618e+00  8.221090e+00]\n",
      " [ 1.017540e-01  4.174291e+00  8.164228e+00]\n",
      " [ 1.239000e-01  4.228160e+00  8.100781e+00]\n",
      " [ 1.448490e-01  4.237138e+00  8.082227e+00]\n",
      " [ 1.562220e-01  4.240131e+00  8.115746e+00]\n",
      " [ 1.137250e-01  4.243722e+00  8.152855e+00]\n",
      " [ 8.679000e-02  4.197634e+00  8.171411e+00]\n",
      " [ 8.200100e-02  4.181473e+00  8.163031e+00]\n",
      " [ 1.167170e-01  4.180276e+00  8.137293e+00]\n",
      " [ 1.616090e-01  4.168904e+00  8.087015e+00]\n",
      " [ 2.250550e-01  4.155735e+00  8.055890e+00]\n",
      " [ 2.980780e-01  4.138378e+00  8.022970e+00]\n",
      " [ 2.513910e-01  4.150349e+00  7.981670e+00]\n",
      " [ 1.616090e-01  4.151546e+00  7.918223e+00]\n",
      " [ 1.628060e-01  4.176685e+00  7.937976e+00]\n",
      " [ 2.448070e-01  4.170101e+00  8.015787e+00]\n",
      " [ 3.800800e-01  4.129399e+00  8.047510e+00]\n",
      " [ 4.632780e-01  4.097078e+00  8.043920e+00]\n",
      " [ 6.117190e-01  4.042011e+00  8.031948e+00]\n",
      " [ 7.260420e-01  4.015675e+00  8.009802e+00]\n",
      " [ 7.966710e-01  3.973776e+00  8.005612e+00]\n",
      " [ 8.367730e-01  3.938462e+00  7.995437e+00]\n",
      " [ 8.349780e-01  3.919308e+00  8.018780e+00]\n",
      " [ 8.325840e-01  3.931279e+00  8.093599e+00]\n",
      " [ 7.936780e-01  3.912724e+00  8.118139e+00]\n",
      " [ 8.128310e-01  3.891775e+00  8.234857e+00]\n",
      " [ 9.086000e-01  3.893570e+00  8.390480e+00]\n",
      " [ 9.522940e-01  3.936666e+00  8.429385e+00]\n",
      " [ 9.522940e-01  3.985747e+00  8.388684e+00]\n",
      " [ 9.277530e-01  4.080318e+00  8.234857e+00]\n",
      " [ 9.349360e-01  4.271256e+00  8.025364e+00]\n",
      " [ 9.947910e-01  4.360440e+00  7.914632e+00]\n",
      " [ 1.044471e+00  4.444836e+00  7.861960e+00]\n",
      " [ 1.041478e+00  4.502296e+00  7.835025e+00]\n",
      " [ 1.015740e+00  4.551976e+00  7.828441e+00]\n",
      " [ 9.702500e-01  4.589086e+00  7.808090e+00]\n",
      " [ 9.151840e-01  4.596867e+00  7.885902e+00]\n",
      " [ 8.170210e-01  4.575319e+00  7.979276e+00]\n",
      " [ 7.392100e-01  4.580707e+00  8.150461e+00]\n",
      " [ 6.649900e-01  4.542998e+00  8.287529e+00]\n",
      " [ 6.087260e-01  4.544794e+00  8.380304e+00]\n",
      " [ 5.782000e-01  4.556166e+00  8.406042e+00]\n",
      " [ 5.285200e-01  4.566341e+00  8.344392e+00]\n",
      " [ 4.860230e-01  4.560954e+00  8.275558e+00]\n",
      " [ 4.842270e-01  4.556166e+00  8.218098e+00]\n",
      " [ 5.249290e-01  4.577115e+00  8.165425e+00]\n",
      " [ 5.225350e-01  4.563947e+00  8.097789e+00]\n",
      " [ 5.488710e-01  4.599261e+00  7.820660e+00]\n",
      " [ 5.614400e-01  4.603451e+00  7.671621e+00]\n",
      " [ 6.003460e-01  4.627393e+00  7.542334e+00]\n",
      " [ 6.111200e-01  4.623203e+00  7.452551e+00]\n",
      " [ 6.326680e-01  4.607641e+00  7.462128e+00]\n",
      " [ 6.560110e-01  4.544195e+00  7.513005e+00]\n",
      " [ 6.931210e-01  4.493318e+00  7.593211e+00]\n",
      " [ 7.948750e-01  4.420295e+00  7.628525e+00]\n",
      " [ 8.367730e-01  4.350863e+00  7.630920e+00]\n",
      " [ 8.720880e-01  4.334104e+00  7.613562e+00]\n",
      " [ 8.876500e-01  4.314352e+00  7.611167e+00]\n",
      " [ 8.625110e-01  4.328717e+00  7.721899e+00]\n",
      " [ 8.391680e-01  4.282628e+00  8.456321e+00]\n",
      " [ 4.231750e-01  4.204218e+00  8.072051e+00]\n",
      " [ 1.879450e-01  4.510078e+00  6.959346e+00]\n",
      " [ 4.447230e-01  4.624999e+00  6.514024e+00]\n",
      " [ 8.475470e-01  4.206014e+00  8.112753e+00]\n",
      " [ 4.477160e-01  4.116830e+00  8.847773e+00]\n",
      " [ 1.729810e-01  4.100669e+00  9.036914e+00]\n",
      " [ 2.005140e-01  4.171896e+00  8.890868e+00]\n",
      " [ 3.872620e-01  4.310760e+00  8.664616e+00]\n",
      " [ 5.171480e-01  4.523844e+00  8.335413e+00]\n",
      " [ 5.476740e-01  4.668693e+00  7.960122e+00]\n",
      " [ 5.434840e-01  4.795586e+00  7.796718e+00]\n",
      " [ 4.967970e-01  4.870405e+00  7.776966e+00]\n",
      " [ 4.333510e-01  4.882974e+00  7.876924e+00]\n",
      " [ 3.333930e-01  4.896142e+00  7.933786e+00]\n",
      " [ 2.914940e-01  4.866814e+00  7.913435e+00]\n",
      " [ 3.052610e-01  4.827908e+00  7.903260e+00]\n",
      " [ 2.998740e-01  4.789002e+00  7.908647e+00]\n",
      " [ 2.843110e-01  4.756680e+00  8.006210e+00]\n",
      " [ 2.310400e-01  4.661511e+00  8.165425e+00]\n",
      " [ 1.885430e-01  4.560356e+00  8.464102e+00]\n",
      " [ 1.795650e-01  4.347870e+00  8.534132e+00]\n",
      " [ 3.088520e-01  4.271854e+00  8.619724e+00]\n",
      " [ 4.459200e-01  4.210204e+00  8.650849e+00]\n",
      " [ 5.285200e-01  4.182671e+00  8.673594e+00]]\n",
      "[-0.21512032  4.72867125  8.012724  ]\n",
      "[0.83490818 1.20696915 1.06745706]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "#it means that we want to have 150 features per sample\n",
    "minimum_of_data_in_csv = 150\n",
    "data = np.zeros((minimum_of_data_in_csv, 3))\n",
    "data = np.zeros((minimum_of_data_in_csv, 3))\n",
    "i = 10003\n",
    "maximum_file_name = 23999\n",
    "\n",
    "while i <= maximum_file_name:\n",
    "    if exists('./train/train/' + str(i) + '.csv'):        \n",
    "        with open('./train/train/' + str(i) + '.csv', 'r') as file:\n",
    "            r = csv.reader(file)\n",
    "            j = 0\n",
    "            for row in r:\n",
    "                if j < minimum_of_data_in_csv:\n",
    "                    data[j] = np.array([float(i) for i in row])\n",
    "                    j += 1\n",
    "\n",
    "        added_data = np.copy(add_features(data, j, k=3))\n",
    "        train_data.append(np.copy(added_data))\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "print(train_data[0])\n",
    "train_data = np.array(train_data)\n",
    "#scale the data using SD\n",
    "train_data = scale_SD(train_data)\n",
    "n = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333f5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0:7000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cfc4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "with open('./train_labels.csv', 'r') as file:\n",
    "    r = csv.reader(file)\n",
    "    first_row = 0\n",
    "    for row in r:\n",
    "        if first_row == 0:\n",
    "            first_row = 1\n",
    "            continue\n",
    "        train_labels.append([int(i) for i in row])\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "still-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(150, 3)), \n",
    "  tf.keras.layers.Dense(8192, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(4096, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(2048, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(256, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "  tf.keras.layers.Dense(20, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "facial-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 450)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8192)              3694592   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 8192)             32768     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              33558528  \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              8390656   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              2098176   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 20)                660       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,507,380\n",
      "Trainable params: 48,474,676\n",
      "Non-trainable params: 32,704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3044f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)  \n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53b820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.2200 - accuracy: 0.9316\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.2278 - accuracy: 0.9301\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1953 - accuracy: 0.9396\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.2242 - accuracy: 0.9296\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1753 - accuracy: 0.9459\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.1839 - accuracy: 0.9449\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1896 - accuracy: 0.9399\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.1626 - accuracy: 0.9513\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1602 - accuracy: 0.9511\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1816 - accuracy: 0.9421\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1704 - accuracy: 0.9497\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1410 - accuracy: 0.9557\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1451 - accuracy: 0.9561\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1566 - accuracy: 0.9530\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1553 - accuracy: 0.9519\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.1207 - accuracy: 0.9636\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.1532 - accuracy: 0.9536\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1378 - accuracy: 0.9593\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 4s 23ms/step - loss: 0.1396 - accuracy: 0.9550\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 4s 22ms/step - loss: 0.1387 - accuracy: 0.9549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce68196f48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data[0:7000], train_labels[0:7000, 1]-1,\n",
    "          epochs=50, batch_size=40, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acute-foster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(train_data[7000:9000])\n",
    "predicted_labels_validation = np.argmax(predict, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tender-constraint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 20 13 ... 13 13 18]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels_validation)\n",
    "confusion_matrix = np.zeros((20, 20), dtype=int)\n",
    "validation_labels = train_labels[7000:9000, 1]\n",
    "for i in range(len(predicted_labels_validation)):\n",
    "    confusion_matrix[validation_labels[i] - 1][predicted_labels_validation[i] - 1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "intellectual-empire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73  1  0  0  0  0  7  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      "[ 0 95  0  0  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      "[ 0  0 88  0  0  0  0  0  9  0  0  5  5  0  0  0  0  0  2  0]\n",
      "[ 0 34  0 68  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 0  0  0  0 94  0  0  0  8  0  0  5 19  0  0  0  0  0  0  0]\n",
      "[ 0  2  0  0  0 86  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[  3   0   0   0   0   0 112   0   0   2   0   0   0   0   2   0   0   0\n",
      "   0   0]\n",
      "[ 0  0  0  0  0  0  0 94  0  0  0  0  0  8  0  0  0  0  0  1]\n",
      "[ 0  0  0  0  1  0  0  0 78  0  0  9  4  0  0  0  2  0  0  0]\n",
      "[ 0  7  0  0  0  2  0  0  0 98  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0 98  0  0  0  0  0  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0 69  0  0  0  0  0  0  0  0]\n",
      "[ 0  0  4  0  3  0  0  0  2  0  0  6 88  0  0  0  3  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  3  0  0  0  0  0 98  0  0  0  0  0  0]\n",
      "[ 0  6  0  1  0  2  0  0  0  1  0  0  0  0 85  0  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0  0  0  0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  9  1  0  0  0 93  0  1  0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 104\n",
      "   0   1]\n",
      "[ 0  0 16  0  0  0  0  0  2  0  0  1  4  0  0  0  9  0 69  0]\n",
      "[ 0  2  0  1  0  0  1  0  0  0  1  0  0  0  0  0  0  1  0 89]\n"
     ]
    }
   ],
   "source": [
    "for row in confusion_matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "settled-mainstream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "180/180 [==============================] - 6s 22ms/step - loss: 1.6390 - accuracy: 0.4896\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 1.0936 - accuracy: 0.6297\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.9277 - accuracy: 0.6824\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 20s 110ms/step - loss: 0.8059 - accuracy: 0.7217\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6912 - accuracy: 0.7676\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6212 - accuracy: 0.7981\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5684 - accuracy: 0.8163\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5234 - accuracy: 0.8313\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4820 - accuracy: 0.8401\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4714 - accuracy: 0.8487\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4427 - accuracy: 0.8578\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3927 - accuracy: 0.8740\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4147 - accuracy: 0.8685\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3657 - accuracy: 0.8850\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3693 - accuracy: 0.8842\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3410 - accuracy: 0.8929\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3284 - accuracy: 0.8981\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3171 - accuracy: 0.9007\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.3079 - accuracy: 0.9039\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2897 - accuracy: 0.9089\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2827 - accuracy: 0.9082\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2959 - accuracy: 0.9092\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2455 - accuracy: 0.9240\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2506 - accuracy: 0.9194\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2542 - accuracy: 0.9215\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2350 - accuracy: 0.9261\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2099 - accuracy: 0.9346\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2105 - accuracy: 0.9340\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1945 - accuracy: 0.9417\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2381 - accuracy: 0.9271\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1996 - accuracy: 0.9368\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1821 - accuracy: 0.9419\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2245 - accuracy: 0.9297\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1695 - accuracy: 0.9468\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2006 - accuracy: 0.9372\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1610 - accuracy: 0.9511\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1789 - accuracy: 0.9443\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1706 - accuracy: 0.9471\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1593 - accuracy: 0.9536\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1543 - accuracy: 0.9532\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1520 - accuracy: 0.9540\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1528 - accuracy: 0.9526\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1677 - accuracy: 0.9507\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1225 - accuracy: 0.9632\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1297 - accuracy: 0.9589\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1733 - accuracy: 0.9451\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1261 - accuracy: 0.9628\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1095 - accuracy: 0.9657\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1325 - accuracy: 0.9625\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1163 - accuracy: 0.9626\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 6s 25ms/step - loss: 1.6075 - accuracy: 0.5026\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 1.0445 - accuracy: 0.6450\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.8454 - accuracy: 0.7104\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.7427 - accuracy: 0.7556\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.6473 - accuracy: 0.7876\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.5989 - accuracy: 0.8046\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.5565 - accuracy: 0.8161\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.5038 - accuracy: 0.8367\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4807 - accuracy: 0.8482\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4747 - accuracy: 0.8504\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4303 - accuracy: 0.8642\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.4085 - accuracy: 0.8725\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.3738 - accuracy: 0.8847\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3770 - accuracy: 0.8801\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3578 - accuracy: 0.8890\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3507 - accuracy: 0.8894\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3044 - accuracy: 0.9032\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3209 - accuracy: 0.9025\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3280 - accuracy: 0.9015\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2692 - accuracy: 0.9139\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.2692 - accuracy: 0.9197\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.2414 - accuracy: 0.9264\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 5s 29ms/step - loss: 0.2928 - accuracy: 0.9119\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2341 - accuracy: 0.9231\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.2602 - accuracy: 0.9160\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2354 - accuracy: 0.9260\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2027 - accuracy: 0.9374\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2260 - accuracy: 0.9343\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2116 - accuracy: 0.9351\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2211 - accuracy: 0.9329\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1979 - accuracy: 0.9354\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1926 - accuracy: 0.9419\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1824 - accuracy: 0.9417\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.2219 - accuracy: 0.9303\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1545 - accuracy: 0.9472\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.2019 - accuracy: 0.9397\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1517 - accuracy: 0.9532\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1779 - accuracy: 0.9476\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1538 - accuracy: 0.9529\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1679 - accuracy: 0.9507\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.1748 - accuracy: 0.9471\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1229 - accuracy: 0.9635\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1587 - accuracy: 0.9510\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1378 - accuracy: 0.9571\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1364 - accuracy: 0.9592\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1533 - accuracy: 0.9564\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1186 - accuracy: 0.9651\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1292 - accuracy: 0.9611\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1365 - accuracy: 0.9586\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.1353 - accuracy: 0.9581\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 7s 25ms/step - loss: 1.5850 - accuracy: 0.5229\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 1.0235 - accuracy: 0.6529\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.8982 - accuracy: 0.6853\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.7627 - accuracy: 0.7389\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.6740 - accuracy: 0.7749\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.6244 - accuracy: 0.7943\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.5479 - accuracy: 0.8157\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.5395 - accuracy: 0.8222\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4938 - accuracy: 0.8464\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4781 - accuracy: 0.8507\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4344 - accuracy: 0.8603\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4081 - accuracy: 0.8692\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3806 - accuracy: 0.8742\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3464 - accuracy: 0.8918\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3732 - accuracy: 0.8807\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3519 - accuracy: 0.8853\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.3344 - accuracy: 0.8942\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3050 - accuracy: 0.9004\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.3246 - accuracy: 0.8932\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2947 - accuracy: 0.9065\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2770 - accuracy: 0.9153\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.2594 - accuracy: 0.9183\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2787 - accuracy: 0.9112\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2519 - accuracy: 0.9200\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2577 - accuracy: 0.9204\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2128 - accuracy: 0.9346\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2317 - accuracy: 0.9275\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2214 - accuracy: 0.9333\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2243 - accuracy: 0.9304\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2321 - accuracy: 0.9281\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1920 - accuracy: 0.9396\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1791 - accuracy: 0.9440\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1982 - accuracy: 0.9371\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1724 - accuracy: 0.9474\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1795 - accuracy: 0.9432\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2131 - accuracy: 0.9317\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1999 - accuracy: 0.9383\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1520 - accuracy: 0.9533\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1743 - accuracy: 0.9482\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1616 - accuracy: 0.9500\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1742 - accuracy: 0.9456\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1590 - accuracy: 0.9503\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1363 - accuracy: 0.9572\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1224 - accuracy: 0.9626\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1432 - accuracy: 0.9575\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1458 - accuracy: 0.9557\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1260 - accuracy: 0.9625\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1217 - accuracy: 0.9615\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1321 - accuracy: 0.9593\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.1095 - accuracy: 0.9671\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 7s 26ms/step - loss: 1.5600 - accuracy: 0.5292\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 1.0469 - accuracy: 0.6479\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.9063 - accuracy: 0.6918\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.7862 - accuracy: 0.7356\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.6808 - accuracy: 0.7783\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6199 - accuracy: 0.7960\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5934 - accuracy: 0.8035\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.5422 - accuracy: 0.8275\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4926 - accuracy: 0.8408\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.4552 - accuracy: 0.8537\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4566 - accuracy: 0.8535\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4346 - accuracy: 0.8579\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.3703 - accuracy: 0.8776\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3724 - accuracy: 0.8807\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3599 - accuracy: 0.8833\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3631 - accuracy: 0.8815\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3132 - accuracy: 0.9049\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3310 - accuracy: 0.8897\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2729 - accuracy: 0.9144\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3092 - accuracy: 0.9014\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2854 - accuracy: 0.9087\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2858 - accuracy: 0.9085\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2558 - accuracy: 0.9193\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2654 - accuracy: 0.9175\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2520 - accuracy: 0.9214\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2480 - accuracy: 0.9219\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2238 - accuracy: 0.9310\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2310 - accuracy: 0.9253\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2459 - accuracy: 0.9203\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2097 - accuracy: 0.9349\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2296 - accuracy: 0.9297\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1860 - accuracy: 0.9397\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1938 - accuracy: 0.9422\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2046 - accuracy: 0.9344\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1710 - accuracy: 0.9483\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1826 - accuracy: 0.9433\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1898 - accuracy: 0.9399\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1880 - accuracy: 0.9419\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1623 - accuracy: 0.9481\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1561 - accuracy: 0.9531\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1524 - accuracy: 0.9511\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1442 - accuracy: 0.9564\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1476 - accuracy: 0.9521\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1516 - accuracy: 0.9564\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1489 - accuracy: 0.9529\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1404 - accuracy: 0.9579\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1373 - accuracy: 0.9579\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1558 - accuracy: 0.9522\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1343 - accuracy: 0.9607\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1215 - accuracy: 0.9636\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 6s 25ms/step - loss: 1.5880 - accuracy: 0.5018\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 1.0281 - accuracy: 0.6428\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.8966 - accuracy: 0.6928\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.7332 - accuracy: 0.7596\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.6345 - accuracy: 0.7864\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.5958 - accuracy: 0.7996\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.5737 - accuracy: 0.8112\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5268 - accuracy: 0.8250\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.5032 - accuracy: 0.8346\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4803 - accuracy: 0.8464\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4176 - accuracy: 0.8676\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3965 - accuracy: 0.8731\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3699 - accuracy: 0.8826\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3523 - accuracy: 0.8846\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3670 - accuracy: 0.8806\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.3254 - accuracy: 0.8975\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.3106 - accuracy: 0.9031\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3061 - accuracy: 0.9035\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3404 - accuracy: 0.8947\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2906 - accuracy: 0.9079\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2885 - accuracy: 0.9118\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2643 - accuracy: 0.9137\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2537 - accuracy: 0.9167\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2755 - accuracy: 0.9147\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2288 - accuracy: 0.9317\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2477 - accuracy: 0.9224\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2480 - accuracy: 0.9232\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2278 - accuracy: 0.9279\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2336 - accuracy: 0.9269\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2238 - accuracy: 0.9300\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.2030 - accuracy: 0.9346\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1902 - accuracy: 0.9375\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.2000 - accuracy: 0.9378\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1864 - accuracy: 0.9401\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 32s 180ms/step - loss: 0.1696 - accuracy: 0.9469\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 86s 480ms/step - loss: 0.1685 - accuracy: 0.9494\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 17s 95ms/step - loss: 0.1835 - accuracy: 0.9428\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.1881 - accuracy: 0.9422\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.1709 - accuracy: 0.9460\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.1865 - accuracy: 0.9425\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1477 - accuracy: 0.9553\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 6s 35ms/step - loss: 0.1712 - accuracy: 0.9463\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.1482 - accuracy: 0.9536\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1552 - accuracy: 0.9540\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1258 - accuracy: 0.9606\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1350 - accuracy: 0.9593\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1290 - accuracy: 0.9590\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1393 - accuracy: 0.9585\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.1232 - accuracy: 0.9626\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1081 - accuracy: 0.9678\n"
     ]
    }
   ],
   "source": [
    "#5-fold cross-validation\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "fold_acc = []\n",
    "splits = [[7200, 9000], [5400, 7200], [3600, 5400], [1800, 3600], [0, 1800]]\n",
    "for split in splits: \n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(150, 3)), \n",
    "      tf.keras.layers.Dense(8192, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(4096, activation='relu'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(2048, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(1024, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(256, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'), \n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(32, activation='relu'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2), \n",
    "      tf.keras.layers.Dense(20, activation='softmax')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=0.001)  \n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    if split[1] == 9000:\n",
    "        data = train_data[:7200]\n",
    "        labels = train_labels[:7200,1]\n",
    "    elif split[0] == 0:\n",
    "        data = train_data[1800:]\n",
    "        labels = train_labels[1800:,1]\n",
    "    else:\n",
    "        data = np.concatenate((train_data[:split[0]], train_data[split[1]:]), axis=0)\n",
    "        labels = np.concatenate((train_labels[:split[0],1], train_labels[split[1]:,1]), axis=0)\n",
    "    validation = train_data[split[0]:split[1]]\n",
    "    validation_labels = train_labels[split[0]:split[1],1]\n",
    "    model.fit(data, labels-1,epochs=50, batch_size=40, initial_epoch=0)\n",
    "    test_loss, test_metrics = model.evaluate(validation, validation_labels - 1, verbose=0)\n",
    "    fold_acc.append(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classified-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs=[]\n",
    "\n",
    "lrs = [0.00001, 0.0001, 0.001, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aquatic-correlation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "200/200 [==============================] - 7s 22ms/step - loss: 2.6301 - accuracy: 0.2504\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.8511 - accuracy: 0.4720\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 1.5634 - accuracy: 0.5816\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 1.3754 - accuracy: 0.6593\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 1.2329 - accuracy: 0.7151\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 1.1208 - accuracy: 0.7582\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 1.0272 - accuracy: 0.7960\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.9305 - accuracy: 0.8317\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.8499 - accuracy: 0.8519\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.8007 - accuracy: 0.8711\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.7539 - accuracy: 0.8880\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.7139 - accuracy: 0.8916\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.6427 - accuracy: 0.9226\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.6004 - accuracy: 0.9277\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5661 - accuracy: 0.9369\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.5432 - accuracy: 0.9421\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.5132 - accuracy: 0.9435\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4762 - accuracy: 0.9574\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4666 - accuracy: 0.9567\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.4394 - accuracy: 0.9632\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.4205 - accuracy: 0.9628\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3963 - accuracy: 0.9676\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3786 - accuracy: 0.9699\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.3540 - accuracy: 0.9753\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.3341 - accuracy: 0.9801\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.3248 - accuracy: 0.9790\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3096 - accuracy: 0.9830\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2970 - accuracy: 0.9810\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2845 - accuracy: 0.9800\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2706 - accuracy: 0.9846\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 7s 25ms/step - loss: 1.7595 - accuracy: 0.5069\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.0955 - accuracy: 0.7312\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.8302 - accuracy: 0.8056\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.6772 - accuracy: 0.8444\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5457 - accuracy: 0.8830\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4920 - accuracy: 0.8889\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.4202 - accuracy: 0.9079\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.3835 - accuracy: 0.9149\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.3485 - accuracy: 0.9208\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.3405 - accuracy: 0.9171\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2980 - accuracy: 0.9310\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2741 - accuracy: 0.9355\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2501 - accuracy: 0.9401\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2437 - accuracy: 0.9406\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.2535 - accuracy: 0.9358\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2274 - accuracy: 0.9452\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2236 - accuracy: 0.9405\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.1958 - accuracy: 0.9494\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 5s 24ms/step - loss: 0.2085 - accuracy: 0.9440\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.1944 - accuracy: 0.9515\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.1882 - accuracy: 0.9520\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.1684 - accuracy: 0.9589\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.1707 - accuracy: 0.9571\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1635 - accuracy: 0.9582\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1387 - accuracy: 0.9654\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1712 - accuracy: 0.9542\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.1572 - accuracy: 0.9585\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.1428 - accuracy: 0.9634\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.1202 - accuracy: 0.9684\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.1221 - accuracy: 0.9679\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 7s 25ms/step - loss: 1.5258 - accuracy: 0.5278\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 1.0157 - accuracy: 0.6544\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.8563 - accuracy: 0.6977\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.7622 - accuracy: 0.7325\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.6458 - accuracy: 0.7840\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 5s 23ms/step - loss: 0.6155 - accuracy: 0.7940\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 0.5697 - accuracy: 0.8145\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.5211 - accuracy: 0.8298\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.4813 - accuracy: 0.8429\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 4s 19ms/step - loss: 0.4645 - accuracy: 0.8505\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.4158 - accuracy: 0.8687\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.3839 - accuracy: 0.8709\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.3849 - accuracy: 0.8799\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.3517 - accuracy: 0.8873\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.3603 - accuracy: 0.8890\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.3389 - accuracy: 0.8930\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2847 - accuracy: 0.9069\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2915 - accuracy: 0.9097\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2698 - accuracy: 0.9103\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.3006 - accuracy: 0.9053\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2966 - accuracy: 0.9066\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2747 - accuracy: 0.9104\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2404 - accuracy: 0.9259\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2355 - accuracy: 0.9241\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2409 - accuracy: 0.9243\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.2085 - accuracy: 0.9339\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2482 - accuracy: 0.9179\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 0.1980 - accuracy: 0.9391\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2041 - accuracy: 0.9342\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 0.2042 - accuracy: 0.9360\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 6s 22ms/step - loss: 8.7001 - accuracy: 0.1231\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 4.5924 - accuracy: 0.1612\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 4s 22ms/step - loss: 11.2082 - accuracy: 0.2249\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 9.1574 - accuracy: 0.2681\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 7.5746 - accuracy: 0.2710\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 6.9004 - accuracy: 0.3180\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 8.0080 - accuracy: 0.3509\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 9.5450 - accuracy: 0.3349\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 10.3779 - accuracy: 0.2926\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 6.8679 - accuracy: 0.3490\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 4.3921 - accuracy: 0.3824\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 4.8067 - accuracy: 0.3944\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 10.4283 - accuracy: 0.3361\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 16.6988 - accuracy: 0.3274\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 14.1596 - accuracy: 0.3525\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 10.6837 - accuracy: 0.3639\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 10.3251 - accuracy: 0.3729\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 7.3095 - accuracy: 0.4126\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 7.6603 - accuracy: 0.4089\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 12.5055 - accuracy: 0.3781\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 17.9962 - accuracy: 0.3716\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 13.7532 - accuracy: 0.3891\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 7.6052 - accuracy: 0.4441\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 4.7771 - accuracy: 0.4760\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 7.4269 - accuracy: 0.4240\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 15.0804 - accuracy: 0.3845\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 13.6934 - accuracy: 0.4171\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 4s 21ms/step - loss: 7.0070 - accuracy: 0.4925\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 7.3431 - accuracy: 0.4613\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 4s 20ms/step - loss: 9.7865 - accuracy: 0.4243\n"
     ]
    }
   ],
   "source": [
    "#lr and acc plot data\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop \n",
    "\n",
    "lrs = [0.00001, 0.0001, 0.001, 1]\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(150, 3)), \n",
    "  tf.keras.layers.Dense(8192, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(4096, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(2048, activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(1024, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(512, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(256, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'), \n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2), \n",
    "  tf.keras.layers.Dense(20, activation='softmax') \n",
    "])\n",
    "model.save_weights('model.h5')\n",
    "for lr in lrs:\n",
    "    model.load_weights('model.h5')\n",
    "    optimizer = Adam(learning_rate=lr)  \n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(train_data[0:8000], train_labels[0:8000,1]-1,epochs=30, batch_size=40, initial_epoch=0)\n",
    "    test_loss, test_metrics = model.evaluate(train_data[8000:9000], train_labels[8000:9000, 1] - 1, verbose=0)\n",
    "    test_accs.append(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spoken-harmony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9079999923706055, 0.9089999794960022, 0.875, 0.367000013589859]\n"
     ]
    }
   ],
   "source": [
    "print(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instructional-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9055555462837219, 0.92166668176651, 0.9188888669013977, 0.9194444417953491, 0.9083333611488342]\n"
     ]
    }
   ],
   "source": [
    "print(fold_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrote it in case it gets erased\n",
    "fold_acc = [0.9055555462837219, 0.92166668176651, 0.9188888669013977, 0.9194444417953491, 0.9083333611488342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "endless-nudist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.1772 - accuracy: 0.9443\n",
      "Epoch 2/5\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1600 - accuracy: 0.9506\n",
      "Epoch 3/5\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.1632 - accuracy: 0.9480\n",
      "Epoch 4/5\n",
      "225/225 [==============================] - 5s 20ms/step - loss: 0.1739 - accuracy: 0.9480\n",
      "Epoch 5/5\n",
      "225/225 [==============================] - 4s 20ms/step - loss: 0.1550 - accuracy: 0.9532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ee2c19708>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, train_labels[:,1]-1,\n",
    "          epochs=5, batch_size=40, initial_epoch=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3009b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.07006318122148514\n",
      "test metrics 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_metrics = model.evaluate(train_data[8500:9000], train_labels[8500:9000, 1] - 1, verbose=0) \n",
    "print('test loss', test_loss)\n",
    "print('test metrics', test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2cd6a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "[-0.20556379  4.68430617  8.0491769 ]\n",
      "[0.89727405 1.08385553 1.08536441]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "data = np.zeros((minimum_of_data_in_csv, 3))\n",
    "i = 10001\n",
    "maximum_file_name = 24000\n",
    "while i <= maximum_file_name:\n",
    "    if exists('./test/test/' + str(i) + '.csv'):        \n",
    "        with open('./test/test/' + str(i) + '.csv', 'r') as file:\n",
    "            r = csv.reader(file)\n",
    "            j = 0\n",
    "            for row in r:\n",
    "                if j < minimum_of_data_in_csv:\n",
    "                    data[j] = np.array([float(i) for i in row])\n",
    "                    j += 1\n",
    "        scaled_data = np.copy(add_features(data, j, k=3))\n",
    "        test_data.append(scaled_data)\n",
    "        test_labels.append(i)\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "test_data = np.array(test_data)\n",
    "test_data = scale_SD(test_data)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "n = test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c40fec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(test_data)\n",
    "predicted_labels_test = np.argmax(predict, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ideal-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 ... 4 5 1]\n",
      "[3 4 5 ... 4 5 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predict, axis=1) + 1)\n",
    "print(predicted_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cardiovascular-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare csv data\n",
    "csv_data = [[test_labels[i], predicted_labels_test[i]] for i in range(len(test_labels))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "blank-temperature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10001, 3], [10002, 4], [10004, 5], [10008, 20], [10009, 5], [10010, 13], [10011, 9], [10015, 4], [10023, 5], [10027, 19], [10032, 16], [10034, 9], [10035, 2], [10040, 8], [10041, 17], [10043, 15], [10044, 19], [10045, 5], [10048, 4], [10051, 18], [10057, 17], [10060, 18], [10061, 12], [10063, 7], [10068, 16], [10069, 18], [10073, 8], [10080, 2], [10083, 16], [10084, 3], [10089, 11], [10093, 6], [10095, 10], [10097, 9], [10099, 4], [10102, 19], [10104, 6], [10105, 20], [10107, 5], [10115, 1], [10116, 5], [10118, 10], [10123, 19], [10126, 3], [10127, 1], [10129, 3], [10130, 18], [10131, 18], [10134, 10], [10136, 20], [10137, 17], [10139, 3], [10141, 7], [10147, 4], [10148, 3], [10149, 12], [10151, 16], [10152, 16], [10156, 8], [10157, 17], [10158, 15], [10160, 4], [10162, 19], [10167, 13], [10171, 9], [10175, 13], [10177, 20], [10180, 8], [10182, 4], [10184, 15], [10190, 14], [10194, 20], [10195, 16], [10197, 9], [10198, 12], [10202, 8], [10203, 8], [10204, 20], [10209, 18], [10210, 9], [10223, 19], [10226, 8], [10232, 17], [10235, 8], [10236, 11], [10237, 12], [10241, 19], [10242, 17], [10244, 8], [10246, 17], [10247, 17], [10248, 16], [10250, 8], [10251, 5], [10256, 11], [10259, 1], [10260, 10], [10261, 5], [10263, 5], [10264, 11], [10265, 8], [10267, 16], [10269, 19], [10273, 20], [10276, 14], [10285, 17], [10287, 3], [10291, 19], [10296, 16], [10300, 3], [10301, 19], [10304, 5], [10305, 2], [10309, 8], [10310, 5], [10320, 11], [10322, 17], [10323, 19], [10324, 20], [10325, 10], [10329, 9], [10336, 14], [10337, 20], [10338, 15], [10341, 9], [10351, 9], [10352, 16], [10354, 18], [10357, 17], [10358, 19], [10359, 20], [10361, 7], [10364, 17], [10366, 11], [10369, 2], [10370, 4], [10374, 2], [10375, 5], [10377, 11], [10381, 18], [10382, 8], [10384, 15], [10389, 2], [10390, 19], [10392, 9], [10394, 12], [10402, 20], [10404, 4], [10406, 19], [10409, 4], [10410, 10], [10412, 5], [10414, 16], [10417, 10], [10418, 14], [10420, 14], [10423, 10], [10426, 5], [10427, 7], [10434, 8], [10435, 16], [10441, 20], [10452, 17], [10453, 13], [10461, 19], [10462, 1], [10466, 5], [10467, 2], [10468, 19], [10472, 2], [10476, 19], [10480, 18], [10484, 12], [10485, 2], [10488, 12], [10489, 5], [10493, 10], [10494, 15], [10497, 20], [10498, 14], [10500, 1], [10507, 19], [10511, 9], [10519, 4], [10521, 14], [10524, 15], [10526, 10], [10530, 17], [10535, 4], [10536, 17], [10538, 6], [10539, 15], [10552, 8], [10554, 14], [10556, 18], [10558, 20], [10560, 13], [10564, 9], [10566, 18], [10569, 7], [10570, 17], [10571, 5], [10575, 8], [10577, 10], [10583, 20], [10584, 8], [10585, 4], [10589, 14], [10592, 18], [10594, 17], [10595, 19], [10596, 18], [10601, 5], [10606, 19], [10607, 18], [10613, 20], [10615, 20], [10618, 9], [10621, 9], [10626, 16], [10628, 4], [10629, 4], [10633, 8], [10634, 3], [10638, 8], [10642, 18], [10643, 17], [10644, 8], [10646, 19], [10647, 2], [10653, 19], [10655, 19], [10656, 11], [10657, 13], [10666, 6], [10668, 6], [10669, 16], [10670, 3], [10671, 7], [10676, 2], [10679, 13], [10682, 11], [10684, 12], [10685, 11], [10686, 19], [10687, 1], [10688, 16], [10691, 5], [10693, 7], [10700, 6], [10704, 19], [10705, 9], [10707, 8], [10711, 17], [10716, 10], [10717, 15], [10718, 1], [10719, 3], [10725, 17], [10729, 3], [10730, 18], [10732, 17], [10736, 17], [10737, 18], [10738, 19], [10739, 8], [10744, 14], [10749, 13], [10750, 11], [10751, 3], [10753, 13], [10755, 2], [10756, 20], [10757, 15], [10759, 1], [10760, 19], [10761, 13], [10763, 11], [10767, 8], [10768, 13], [10770, 6], [10772, 6], [10774, 15], [10776, 10], [10777, 10], [10778, 6], [10779, 20], [10783, 5], [10784, 18], [10786, 14], [10795, 15], [10798, 11], [10803, 10], [10806, 6], [10807, 4], [10812, 11], [10814, 18], [10816, 19], [10819, 11], [10821, 5], [10825, 20], [10827, 14], [10832, 17], [10833, 19], [10837, 15], [10838, 13], [10839, 14], [10840, 15], [10842, 12], [10847, 12], [10852, 11], [10854, 1], [10856, 4], [10859, 19], [10861, 12], [10862, 17], [10863, 10], [10865, 6], [10866, 18], [10868, 20], [10870, 3], [10873, 18], [10874, 3], [10875, 19], [10881, 19], [10883, 17], [10885, 2], [10886, 10], [10887, 13], [10888, 11], [10890, 11], [10891, 13], [10892, 15], [10894, 1], [10896, 2], [10900, 10], [10905, 20], [10908, 18], [10910, 18], [10917, 16], [10920, 6], [10926, 4], [10938, 7], [10943, 14], [10946, 15], [10950, 13], [10952, 10], [10953, 3], [10957, 16], [10958, 10], [10959, 10], [10962, 19], [10965, 1], [10966, 20], [10967, 15], [10970, 11], [10972, 6], [10974, 17], [10979, 15], [10980, 10], [10986, 6], [10988, 14], [10989, 13], [10990, 18], [10996, 18], [10997, 9], [10999, 10], [11003, 16], [11006, 6], [11015, 9], [11016, 1], [11022, 4], [11023, 6], [11025, 16], [11030, 8], [11032, 6], [11037, 18], [11039, 11], [11048, 11], [11051, 17], [11052, 10], [11054, 2], [11055, 6], [11059, 5], [11061, 16], [11066, 7], [11069, 15], [11073, 2], [11075, 13], [11080, 14], [11085, 19], [11091, 15], [11096, 8], [11100, 7], [11101, 10], [11103, 19], [11104, 3], [11107, 8], [11108, 14], [11122, 19], [11124, 4], [11125, 3], [11126, 12], [11132, 8], [11134, 10], [11136, 10], [11141, 20], [11144, 20], [11145, 3], [11152, 11], [11154, 20], [11156, 7], [11159, 18], [11162, 11], [11165, 4], [11166, 17], [11170, 8], [11172, 18], [11175, 7], [11177, 5], [11179, 11], [11181, 14], [11187, 20], [11188, 1], [11189, 5], [11191, 10], [11197, 7], [11201, 8], [11203, 18], [11206, 20], [11207, 18], [11210, 2], [11214, 10], [11223, 20], [11225, 4], [11226, 17], [11228, 1], [11229, 7], [11233, 5], [11236, 4], [11237, 19], [11238, 6], [11240, 10], [11242, 4], [11246, 14], [11249, 13], [11251, 13], [11254, 16], [11263, 16], [11265, 14], [11269, 18], [11272, 18], [11274, 4], [11277, 3], [11281, 14], [11282, 2], [11284, 2], [11285, 15], [11286, 19], [11289, 9], [11291, 4], [11293, 1], [11294, 6], [11298, 15], [11302, 20], [11307, 4], [11311, 4], [11312, 1], [11315, 14], [11316, 2], [11317, 5], [11318, 16], [11322, 17], [11329, 1], [11330, 7], [11332, 16], [11333, 6], [11335, 2], [11337, 15], [11338, 8], [11342, 1], [11343, 17], [11352, 10], [11353, 13], [11354, 17], [11355, 1], [11357, 11], [11358, 12], [11359, 1], [11360, 7], [11361, 10], [11362, 2], [11365, 3], [11366, 16], [11367, 8], [11372, 5], [11374, 4], [11376, 15], [11381, 8], [11382, 17], [11388, 6], [11392, 9], [11393, 8], [11394, 3], [11397, 18], [11400, 11], [11401, 18], [11404, 11], [11411, 19], [11415, 7], [11416, 1], [11417, 5], [11418, 12], [11419, 11], [11424, 17], [11427, 11], [11430, 13], [11432, 7], [11435, 8], [11436, 2], [11439, 14], [11440, 9], [11442, 10], [11445, 3], [11447, 6], [11450, 5], [11452, 19], [11457, 2], [11458, 20], [11459, 1], [11462, 8], [11463, 14], [11464, 1], [11465, 18], [11470, 9], [11472, 11], [11474, 2], [11476, 9], [11482, 18], [11484, 5], [11491, 13], [11492, 19], [11494, 14], [11500, 7], [11504, 10], [11508, 5], [11512, 19], [11513, 12], [11517, 18], [11520, 19], [11522, 3], [11530, 20], [11533, 9], [11540, 4], [11543, 11], [11545, 6], [11546, 15], [11550, 7], [11551, 9], [11554, 2], [11556, 6], [11562, 14], [11566, 9], [11574, 18], [11575, 19], [11576, 11], [11578, 16], [11579, 7], [11591, 13], [11593, 1], [11594, 5], [11595, 9], [11597, 11], [11604, 15], [11606, 3], [11610, 12], [11612, 13], [11613, 2], [11614, 13], [11615, 10], [11617, 8], [11621, 4], [11624, 7], [11629, 6], [11634, 8], [11642, 4], [11643, 19], [11647, 9], [11650, 15], [11651, 13], [11657, 15], [11659, 16], [11667, 8], [11673, 18], [11675, 19], [11678, 19], [11680, 19], [11681, 17], [11683, 18], [11684, 18], [11685, 5], [11688, 17], [11691, 6], [11693, 4], [11694, 6], [11695, 1], [11697, 3], [11700, 5], [11704, 13], [11705, 2], [11712, 17], [11713, 1], [11716, 14], [11719, 20], [11723, 17], [11726, 10], [11732, 11], [11733, 10], [11737, 18], [11739, 11], [11748, 2], [11750, 2], [11756, 19], [11759, 5], [11764, 10], [11766, 4], [11767, 16], [11769, 18], [11775, 19], [11777, 6], [11778, 9], [11779, 13], [11783, 18], [11786, 16], [11787, 7], [11789, 7], [11792, 7], [11795, 2], [11796, 10], [11798, 12], [11820, 15], [11821, 5], [11823, 7], [11824, 19], [11834, 13], [11835, 3], [11839, 1], [11841, 2], [11842, 18], [11844, 1], [11846, 20], [11847, 8], [11849, 17], [11851, 4], [11852, 17], [11856, 5], [11857, 17], [11859, 4], [11860, 2], [11866, 19], [11867, 18], [11868, 19], [11872, 1], [11875, 11], [11883, 8], [11887, 19], [11888, 11], [11891, 6], [11895, 5], [11898, 18], [11903, 15], [11904, 14], [11912, 2], [11913, 19], [11916, 3], [11920, 5], [11921, 5], [11923, 19], [11924, 9], [11925, 20], [11926, 2], [11927, 14], [11935, 15], [11939, 2], [11941, 4], [11942, 12], [11944, 11], [11945, 15], [11946, 20], [11947, 17], [11948, 15], [11949, 11], [11950, 7], [11952, 2], [11953, 10], [11954, 5], [11961, 17], [11962, 6], [11963, 10], [11964, 10], [11965, 18], [11966, 2], [11971, 11], [11974, 15], [11982, 9], [11984, 20], [11985, 1], [11986, 19], [11987, 17], [11988, 10], [11990, 2], [11991, 1], [11992, 15], [11993, 4], [11996, 7], [11998, 20], [11999, 11], [12001, 15], [12002, 13], [12004, 20], [12008, 18], [12009, 11], [12011, 12], [12018, 9], [12020, 3], [12021, 6], [12024, 2], [12029, 15], [12030, 15], [12035, 5], [12038, 5], [12039, 1], [12049, 2], [12052, 6], [12053, 15], [12054, 13], [12058, 4], [12062, 1], [12064, 19], [12072, 15], [12074, 9], [12081, 6], [12082, 16], [12087, 10], [12089, 5], [12091, 6], [12093, 16], [12094, 20], [12095, 14], [12099, 16], [12100, 2], [12101, 1], [12102, 19], [12105, 6], [12106, 12], [12112, 20], [12114, 17], [12121, 19], [12124, 14], [12127, 13], [12129, 9], [12130, 2], [12132, 20], [12133, 17], [12149, 19], [12152, 15], [12156, 8], [12157, 11], [12158, 20], [12159, 17], [12160, 6], [12161, 8], [12166, 8], [12170, 17], [12171, 12], [12172, 14], [12175, 16], [12176, 16], [12179, 4], [12184, 15], [12188, 5], [12190, 3], [12196, 11], [12197, 12], [12198, 18], [12201, 15], [12203, 17], [12205, 15], [12206, 10], [12208, 15], [12209, 19], [12211, 19], [12215, 10], [12217, 10], [12218, 4], [12219, 16], [12224, 16], [12227, 2], [12231, 4], [12233, 18], [12234, 2], [12237, 4], [12240, 8], [12242, 9], [12243, 7], [12248, 18], [12251, 5], [12268, 1], [12280, 5], [12282, 3], [12286, 7], [12287, 5], [12289, 9], [12290, 17], [12294, 7], [12299, 7], [12301, 10], [12302, 5], [12306, 16], [12308, 20], [12311, 9], [12318, 16], [12323, 6], [12326, 15], [12329, 16], [12334, 14], [12336, 15], [12337, 18], [12339, 5], [12340, 7], [12342, 4], [12343, 5], [12344, 11], [12348, 17], [12359, 19], [12361, 4], [12362, 10], [12363, 9], [12365, 20], [12368, 16], [12374, 19], [12375, 13], [12377, 11], [12378, 11], [12380, 16], [12387, 8], [12388, 13], [12389, 11], [12390, 14], [12397, 17], [12398, 13], [12401, 19], [12404, 7], [12405, 18], [12408, 4], [12409, 16], [12410, 14], [12412, 9], [12413, 5], [12414, 18], [12416, 10], [12417, 16], [12420, 5], [12421, 19], [12428, 13], [12433, 5], [12440, 11], [12441, 11], [12444, 18], [12445, 17], [12447, 2], [12448, 9], [12450, 12], [12452, 20], [12454, 14], [12457, 5], [12461, 7], [12464, 11], [12465, 4], [12467, 7], [12469, 19], [12471, 17], [12472, 5], [12473, 8], [12475, 7], [12476, 9], [12479, 10], [12483, 3], [12487, 9], [12490, 9], [12493, 1], [12495, 16], [12496, 20], [12499, 19], [12504, 3], [12507, 14], [12510, 19], [12512, 1], [12513, 4], [12514, 19], [12520, 9], [12521, 13], [12526, 3], [12531, 5], [12532, 2], [12533, 17], [12537, 15], [12540, 12], [12543, 13], [12544, 15], [12549, 3], [12550, 8], [12553, 5], [12559, 8], [12560, 15], [12562, 3], [12565, 14], [12571, 10], [12573, 5], [12583, 4], [12585, 7], [12586, 16], [12594, 17], [12596, 13], [12598, 20], [12602, 18], [12606, 12], [12610, 14], [12615, 13], [12618, 19], [12621, 18], [12623, 20], [12624, 1], [12629, 20], [12631, 13], [12632, 14], [12640, 12], [12641, 1], [12642, 7], [12645, 17], [12646, 6], [12648, 19], [12650, 1], [12664, 6], [12665, 2], [12666, 10], [12669, 4], [12670, 6], [12671, 4], [12673, 12], [12675, 15], [12676, 13], [12677, 17], [12679, 15], [12680, 5], [12682, 4], [12686, 12], [12691, 6], [12696, 11], [12698, 6], [12703, 1], [12709, 10], [12710, 16], [12714, 4], [12717, 12], [12719, 10], [12720, 10], [12722, 2], [12725, 8], [12726, 16], [12729, 9], [12731, 18], [12733, 19], [12734, 20], [12736, 20], [12737, 12], [12738, 19], [12739, 5], [12743, 14], [12744, 2], [12746, 1], [12748, 8], [12749, 11], [12751, 11], [12752, 19], [12753, 11], [12754, 4], [12756, 17], [12762, 20], [12764, 5], [12765, 8], [12770, 9], [12771, 3], [12773, 2], [12779, 3], [12787, 18], [12788, 8], [12790, 5], [12791, 5], [12792, 11], [12795, 14], [12798, 18], [12800, 5], [12807, 7], [12809, 12], [12810, 10], [12812, 1], [12815, 18], [12816, 17], [12822, 2], [12823, 16], [12829, 4], [12830, 6], [12832, 13], [12833, 11], [12836, 1], [12837, 15], [12839, 7], [12843, 6], [12846, 1], [12847, 2], [12849, 18], [12853, 2], [12859, 19], [12861, 19], [12865, 8], [12866, 19], [12867, 10], [12869, 16], [12872, 1], [12873, 8], [12877, 16], [12878, 15], [12879, 17], [12882, 20], [12883, 8], [12885, 7], [12887, 14], [12888, 6], [12889, 4], [12890, 20], [12906, 7], [12907, 8], [12910, 10], [12914, 19], [12916, 4], [12917, 6], [12919, 14], [12920, 19], [12925, 9], [12929, 9], [12934, 18], [12938, 18], [12940, 10], [12941, 2], [12943, 15], [12944, 20], [12948, 11], [12950, 11], [12960, 7], [12962, 20], [12963, 1], [12964, 11], [12966, 15], [12967, 9], [12969, 17], [12970, 8], [12973, 4], [12975, 15], [12977, 6], [12981, 17], [12983, 7], [12984, 10], [12985, 9], [12994, 1], [13000, 3], [13001, 12], [13005, 4], [13006, 6], [13007, 16], [13008, 19], [13010, 3], [13011, 16], [13013, 19], [13014, 17], [13017, 5], [13022, 17], [13023, 18], [13032, 19], [13033, 16], [13034, 4], [13035, 3], [13036, 18], [13037, 4], [13045, 6], [13049, 12], [13050, 6], [13051, 4], [13058, 3], [13063, 14], [13065, 8], [13067, 3], [13068, 17], [13069, 8], [13072, 8], [13074, 6], [13075, 13], [13076, 14], [13079, 12], [13081, 4], [13090, 1], [13092, 10], [13096, 6], [13097, 19], [13099, 7], [13106, 5], [13108, 3], [13116, 7], [13117, 3], [13119, 10], [13123, 19], [13129, 11], [13136, 9], [13137, 14], [13138, 19], [13139, 15], [13143, 19], [13145, 20], [13146, 10], [13147, 1], [13149, 19], [13153, 10], [13154, 16], [13157, 20], [13160, 8], [13163, 9], [13168, 17], [13169, 15], [13171, 11], [13172, 8], [13176, 19], [13186, 18], [13190, 18], [13194, 14], [13196, 4], [13198, 4], [13200, 9], [13205, 3], [13209, 1], [13215, 15], [13217, 2], [13220, 10], [13223, 5], [13225, 20], [13226, 17], [13227, 4], [13228, 2], [13233, 12], [13235, 2], [13236, 2], [13237, 8], [13238, 7], [13243, 3], [13244, 19], [13251, 8], [13253, 11], [13257, 2], [13258, 20], [13259, 20], [13263, 6], [13266, 14], [13272, 4], [13275, 15], [13278, 5], [13281, 8], [13284, 10], [13288, 11], [13292, 19], [13295, 8], [13296, 1], [13300, 19], [13306, 18], [13307, 12], [13314, 7], [13315, 17], [13318, 14], [13319, 12], [13323, 20], [13325, 4], [13327, 2], [13328, 9], [13331, 18], [13335, 5], [13337, 2], [13339, 5], [13340, 16], [13349, 9], [13352, 7], [13355, 20], [13361, 18], [13362, 4], [13366, 11], [13376, 19], [13381, 17], [13383, 6], [13384, 18], [13385, 7], [13388, 7], [13390, 1], [13392, 19], [13393, 16], [13394, 19], [13398, 14], [13401, 2], [13402, 5], [13404, 12], [13405, 8], [13408, 9], [13414, 17], [13415, 11], [13416, 5], [13417, 17], [13418, 19], [13432, 8], [13433, 18], [13434, 7], [13435, 1], [13440, 14], [13443, 4], [13445, 2], [13446, 6], [13448, 11], [13451, 20], [13453, 13], [13455, 7], [13456, 19], [13457, 20], [13459, 18], [13464, 8], [13468, 19], [13469, 3], [13472, 16], [13473, 16], [13479, 7], [13480, 10], [13484, 12], [13485, 13], [13486, 13], [13488, 13], [13490, 17], [13493, 6], [13494, 8], [13499, 9], [13500, 15], [13501, 14], [13506, 8], [13510, 5], [13511, 8], [13516, 9], [13518, 9], [13523, 11], [13526, 16], [13531, 19], [13534, 12], [13536, 5], [13538, 3], [13541, 16], [13543, 9], [13544, 1], [13545, 13], [13548, 5], [13549, 12], [13550, 19], [13551, 19], [13553, 14], [13560, 13], [13561, 10], [13562, 7], [13567, 19], [13569, 13], [13570, 12], [13572, 12], [13573, 17], [13578, 19], [13580, 4], [13584, 1], [13585, 15], [13586, 17], [13588, 10], [13591, 8], [13593, 19], [13594, 18], [13596, 20], [13597, 13], [13600, 3], [13602, 7], [13605, 4], [13612, 15], [13615, 5], [13616, 16], [13618, 5], [13620, 8], [13621, 10], [13630, 17], [13633, 20], [13638, 13], [13639, 17], [13640, 14], [13646, 10], [13651, 18], [13654, 7], [13655, 13], [13657, 8], [13659, 13], [13660, 5], [13667, 10], [13669, 1], [13670, 16], [13673, 17], [13675, 3], [13678, 20], [13681, 9], [13683, 15], [13685, 8], [13686, 18], [13690, 8], [13700, 3], [13704, 18], [13706, 15], [13708, 14], [13711, 4], [13717, 7], [13718, 9], [13720, 10], [13722, 20], [13724, 3], [13725, 19], [13726, 5], [13731, 16], [13733, 16], [13737, 15], [13738, 14], [13739, 1], [13743, 13], [13744, 7], [13747, 4], [13748, 5], [13751, 19], [13752, 7], [13754, 5], [13755, 5], [13762, 6], [13768, 11], [13769, 10], [13771, 16], [13781, 5], [13782, 3], [13784, 18], [13792, 11], [13794, 20], [13800, 10], [13803, 3], [13808, 6], [13809, 20], [13811, 19], [13814, 5], [13816, 10], [13817, 8], [13824, 11], [13825, 8], [13827, 6], [13829, 18], [13836, 20], [13837, 2], [13840, 2], [13845, 11], [13849, 1], [13851, 2], [13852, 7], [13858, 4], [13865, 18], [13866, 19], [13867, 17], [13874, 20], [13882, 13], [13883, 6], [13888, 5], [13891, 9], [13894, 20], [13896, 5], [13898, 3], [13905, 1], [13906, 19], [13909, 11], [13910, 1], [13912, 18], [13913, 18], [13917, 18], [13920, 13], [13921, 5], [13922, 20], [13923, 19], [13928, 6], [13931, 11], [13933, 3], [13934, 5], [13939, 20], [13941, 17], [13943, 12], [13946, 6], [13951, 18], [13954, 2], [13956, 16], [13960, 14], [13961, 19], [13963, 6], [13967, 19], [13969, 10], [13970, 8], [13971, 19], [13973, 5], [13974, 15], [13975, 17], [13976, 11], [13983, 5], [13984, 14], [13985, 7], [13988, 3], [13989, 5], [13991, 16], [13992, 12], [13998, 8], [14004, 12], [14008, 5], [14009, 7], [14010, 19], [14012, 19], [14014, 10], [14018, 4], [14024, 10], [14028, 15], [14029, 12], [14035, 5], [14049, 9], [14050, 16], [14053, 6], [14054, 10], [14055, 19], [14057, 4], [14061, 4], [14063, 5], [14066, 11], [14067, 10], [14071, 5], [14076, 10], [14077, 19], [14081, 3], [14083, 17], [14084, 17], [14086, 15], [14098, 3], [14101, 3], [14102, 18], [14105, 13], [14107, 4], [14111, 15], [14112, 10], [14113, 16], [14114, 11], [14121, 5], [14125, 7], [14131, 8], [14133, 1], [14139, 18], [14140, 12], [14144, 11], [14146, 17], [14147, 5], [14150, 19], [14152, 4], [14154, 20], [14155, 6], [14158, 11], [14160, 19], [14162, 19], [14163, 11], [14166, 9], [14167, 11], [14171, 10], [14172, 16], [14173, 11], [14184, 4], [14185, 4], [14187, 19], [14188, 8], [14190, 7], [14193, 11], [14195, 19], [14196, 1], [14197, 3], [14200, 16], [14206, 2], [14207, 5], [14208, 4], [14209, 4], [14210, 10], [14214, 9], [14215, 12], [14220, 4], [14222, 10], [14224, 19], [14226, 2], [14229, 1], [14230, 18], [14232, 1], [14233, 20], [14234, 14], [14236, 7], [14241, 14], [14244, 17], [14245, 17], [14246, 7], [14247, 5], [14250, 1], [14251, 20], [14255, 10], [14261, 10], [14262, 20], [14263, 6], [14264, 18], [14269, 7], [14271, 8], [14278, 12], [14279, 2], [14282, 9], [14283, 17], [14284, 19], [14285, 3], [14292, 17], [14294, 14], [14295, 15], [14298, 10], [14299, 16], [14300, 5], [14303, 9], [14304, 19], [14305, 10], [14308, 16], [14311, 2], [14312, 5], [14315, 9], [14318, 19], [14321, 7], [14327, 2], [14330, 14], [14332, 13], [14337, 13], [14340, 17], [14341, 14], [14342, 11], [14345, 9], [14350, 10], [14351, 17], [14352, 11], [14354, 9], [14355, 4], [14357, 2], [14359, 7], [14361, 10], [14363, 2], [14369, 4], [14370, 19], [14373, 7], [14376, 17], [14377, 4], [14378, 10], [14379, 9], [14381, 19], [14385, 18], [14388, 14], [14389, 1], [14390, 11], [14391, 4], [14396, 2], [14399, 11], [14400, 19], [14401, 18], [14404, 4], [14408, 16], [14410, 6], [14425, 18], [14426, 18], [14430, 20], [14431, 3], [14436, 18], [14443, 1], [14445, 11], [14447, 20], [14450, 17], [14452, 3], [14454, 14], [14457, 5], [14458, 13], [14459, 6], [14462, 9], [14463, 13], [14468, 3], [14469, 14], [14471, 12], [14472, 17], [14474, 3], [14476, 13], [14477, 8], [14480, 9], [14482, 13], [14486, 12], [14488, 6], [14489, 16], [14490, 2], [14494, 5], [14504, 7], [14511, 19], [14512, 7], [14513, 8], [14517, 4], [14529, 13], [14532, 17], [14534, 9], [14535, 1], [14536, 8], [14538, 5], [14539, 18], [14540, 8], [14543, 10], [14545, 18], [14547, 2], [14552, 15], [14553, 15], [14555, 11], [14556, 10], [14562, 9], [14563, 9], [14564, 17], [14567, 2], [14572, 3], [14574, 2], [14575, 20], [14585, 19], [14586, 15], [14594, 5], [14597, 2], [14608, 6], [14609, 7], [14615, 16], [14616, 16], [14619, 20], [14620, 13], [14625, 3], [14629, 3], [14631, 12], [14632, 13], [14633, 5], [14635, 19], [14642, 4], [14644, 3], [14646, 14], [14652, 10], [14654, 10], [14655, 13], [14658, 14], [14659, 19], [14662, 9], [14665, 1], [14667, 15], [14669, 18], [14673, 11], [14676, 19], [14677, 4], [14679, 16], [14680, 11], [14681, 17], [14682, 10], [14684, 5], [14685, 9], [14686, 5], [14687, 18], [14688, 13], [14697, 19], [14698, 8], [14699, 19], [14700, 15], [14706, 17], [14707, 9], [14708, 11], [14709, 9], [14716, 10], [14717, 9], [14718, 10], [14721, 4], [14723, 7], [14724, 15], [14728, 11], [14731, 9], [14732, 13], [14734, 7], [14738, 18], [14743, 9], [14745, 19], [14749, 8], [14750, 19], [14751, 14], [14753, 2], [14759, 7], [14760, 1], [14762, 11], [14763, 4], [14766, 1], [14768, 8], [14770, 12], [14771, 17], [14772, 1], [14777, 15], [14779, 20], [14781, 5], [14785, 13], [14786, 6], [14787, 18], [14790, 1], [14792, 7], [14795, 12], [14798, 18], [14800, 3], [14801, 19], [14803, 16], [14812, 8], [14817, 2], [14825, 2], [14828, 14], [14830, 14], [14831, 5], [14840, 19], [14842, 10], [14843, 5], [14845, 18], [14846, 9], [14847, 12], [14848, 16], [14849, 5], [14851, 6], [14852, 15], [14854, 16], [14855, 2], [14856, 12], [14857, 5], [14859, 4], [14861, 7], [14864, 8], [14865, 7], [14872, 4], [14875, 1], [14876, 10], [14878, 1], [14883, 13], [14887, 2], [14890, 9], [14891, 11], [14893, 13], [14895, 3], [14896, 19], [14899, 7], [14903, 19], [14904, 13], [14905, 16], [14907, 19], [14909, 15], [14910, 8], [14911, 11], [14912, 12], [14914, 14], [14919, 8], [14920, 20], [14921, 20], [14922, 20], [14926, 1], [14931, 15], [14933, 15], [14934, 8], [14937, 18], [14939, 17], [14949, 4], [14952, 2], [14954, 19], [14957, 19], [14958, 13], [14959, 4], [14960, 4], [14961, 13], [14971, 4], [14973, 18], [14975, 3], [14976, 14], [14979, 16], [14980, 8], [14981, 17], [14982, 19], [14984, 5], [14986, 13], [14987, 7], [14991, 7], [14993, 13], [14996, 18], [14997, 10], [14998, 20], [14999, 19], [15000, 9], [15002, 20], [15005, 20], [15013, 17], [15014, 5], [15017, 5], [15019, 6], [15020, 19], [15021, 1], [15031, 2], [15036, 20], [15039, 9], [15040, 4], [15050, 4], [15053, 11], [15056, 12], [15057, 11], [15061, 16], [15062, 7], [15063, 1], [15064, 1], [15066, 10], [15067, 3], [15068, 15], [15072, 2], [15075, 8], [15079, 10], [15081, 2], [15083, 18], [15089, 6], [15090, 15], [15091, 18], [15096, 5], [15097, 18], [15102, 5], [15105, 1], [15107, 10], [15108, 1], [15109, 3], [15111, 3], [15113, 5], [15119, 4], [15120, 19], [15121, 14], [15122, 8], [15123, 7], [15124, 3], [15126, 15], [15127, 9], [15129, 14], [15140, 16], [15142, 1], [15144, 5], [15145, 15], [15147, 12], [15149, 2], [15152, 15], [15156, 8], [15157, 12], [15158, 5], [15160, 18], [15162, 17], [15164, 17], [15169, 7], [15172, 19], [15173, 7], [15175, 10], [15181, 7], [15184, 9], [15185, 4], [15187, 5], [15189, 7], [15191, 12], [15192, 11], [15194, 6], [15195, 19], [15197, 2], [15199, 2], [15202, 17], [15207, 13], [15209, 8], [15211, 10], [15214, 19], [15217, 6], [15223, 3], [15224, 11], [15226, 9], [15227, 8], [15228, 5], [15229, 8], [15236, 18], [15243, 7], [15245, 11], [15247, 19], [15252, 6], [15254, 1], [15257, 16], [15258, 5], [15266, 9], [15269, 10], [15276, 19], [15278, 16], [15282, 8], [15285, 4], [15286, 14], [15293, 13], [15304, 4], [15307, 9], [15314, 20], [15315, 17], [15321, 11], [15324, 9], [15325, 15], [15327, 20], [15335, 4], [15345, 4], [15347, 10], [15348, 2], [15353, 2], [15354, 19], [15357, 19], [15361, 4], [15367, 18], [15368, 11], [15369, 7], [15372, 12], [15382, 5], [15383, 19], [15387, 6], [15390, 18], [15393, 19], [15394, 2], [15396, 17], [15397, 7], [15398, 8], [15400, 17], [15403, 18], [15408, 11], [15413, 12], [15418, 16], [15419, 3], [15420, 8], [15421, 2], [15433, 20], [15434, 17], [15435, 17], [15443, 18], [15444, 6], [15446, 10], [15447, 1], [15449, 19], [15450, 20], [15451, 7], [15455, 9], [15456, 8], [15461, 6], [15463, 17], [15464, 4], [15471, 9], [15473, 6], [15475, 4], [15477, 11], [15480, 5], [15481, 3], [15483, 17], [15484, 2], [15486, 6], [15489, 8], [15490, 8], [15503, 10], [15505, 11], [15506, 10], [15512, 6], [15515, 9], [15517, 12], [15518, 11], [15520, 15], [15521, 12], [15524, 19], [15525, 10], [15526, 5], [15528, 5], [15531, 3], [15534, 18], [15536, 19], [15538, 1], [15540, 16], [15545, 4], [15549, 7], [15556, 1], [15558, 2], [15559, 9], [15561, 6], [15562, 8], [15563, 16], [15570, 11], [15573, 13], [15574, 9], [15577, 3], [15578, 16], [15579, 9], [15581, 6], [15586, 5], [15589, 9], [15592, 18], [15594, 18], [15595, 5], [15596, 5], [15598, 18], [15599, 4], [15600, 15], [15607, 20], [15610, 12], [15612, 17], [15616, 14], [15617, 5], [15620, 8], [15621, 5], [15622, 6], [15627, 2], [15628, 3], [15630, 5], [15634, 1], [15635, 14], [15637, 20], [15641, 19], [15644, 19], [15647, 20], [15648, 20], [15650, 6], [15653, 1], [15654, 8], [15655, 14], [15658, 11], [15660, 16], [15664, 4], [15665, 1], [15666, 9], [15669, 11], [15670, 19], [15674, 5], [15676, 6], [15677, 15], [15678, 19], [15686, 18], [15693, 2], [15694, 9], [15705, 3], [15710, 12], [15712, 10], [15717, 17], [15719, 19], [15720, 14], [15724, 18], [15729, 10], [15731, 19], [15732, 16], [15733, 10], [15735, 4], [15738, 5], [15739, 10], [15740, 13], [15741, 9], [15743, 13], [15745, 10], [15748, 17], [15751, 9], [15752, 16], [15756, 6], [15759, 6], [15761, 11], [15764, 10], [15766, 11], [15773, 11], [15775, 10], [15776, 19], [15778, 20], [15779, 11], [15784, 20], [15790, 8], [15792, 10], [15794, 4], [15797, 11], [15799, 2], [15802, 3], [15803, 12], [15804, 2], [15805, 2], [15811, 11], [15816, 4], [15818, 20], [15820, 6], [15823, 15], [15824, 8], [15827, 18], [15829, 1], [15831, 17], [15833, 20], [15834, 5], [15836, 10], [15838, 14], [15840, 4], [15841, 9], [15844, 7], [15848, 11], [15849, 18], [15850, 8], [15853, 11], [15856, 6], [15858, 1], [15859, 7], [15862, 18], [15867, 19], [15870, 9], [15877, 1], [15883, 9], [15884, 3], [15885, 1], [15888, 12], [15889, 4], [15895, 10], [15897, 3], [15904, 5], [15905, 15], [15906, 1], [15908, 7], [15917, 10], [15920, 11], [15921, 6], [15923, 17], [15924, 18], [15929, 18], [15935, 3], [15939, 4], [15940, 17], [15943, 9], [15944, 15], [15949, 2], [15958, 14], [15962, 10], [15965, 7], [15968, 16], [15969, 7], [15970, 12], [15975, 3], [15976, 4], [15993, 11], [15995, 9], [15998, 8], [16000, 16], [16001, 6], [16003, 8], [16005, 19], [16008, 3], [16015, 2], [16017, 9], [16018, 18], [16019, 16], [16020, 11], [16023, 8], [16030, 10], [16036, 9], [16038, 4], [16039, 11], [16041, 14], [16046, 2], [16047, 2], [16050, 1], [16056, 9], [16057, 6], [16060, 2], [16064, 12], [16065, 2], [16070, 2], [16071, 11], [16072, 16], [16073, 2], [16074, 5], [16076, 13], [16079, 9], [16085, 16], [16090, 1], [16093, 13], [16097, 6], [16098, 1], [16101, 14], [16103, 4], [16107, 11], [16112, 17], [16114, 10], [16117, 7], [16119, 9], [16122, 9], [16123, 9], [16124, 4], [16125, 11], [16126, 9], [16128, 15], [16131, 19], [16139, 5], [16144, 17], [16150, 18], [16151, 8], [16152, 6], [16153, 14], [16156, 15], [16157, 18], [16160, 10], [16165, 17], [16168, 3], [16169, 5], [16171, 17], [16172, 12], [16175, 5], [16176, 7], [16181, 2], [16182, 11], [16188, 2], [16193, 10], [16198, 10], [16203, 1], [16209, 1], [16212, 13], [16215, 17], [16216, 11], [16220, 5], [16223, 13], [16224, 18], [16225, 19], [16235, 15], [16243, 13], [16246, 10], [16251, 10], [16255, 1], [16258, 6], [16260, 5], [16262, 13], [16265, 16], [16267, 10], [16271, 7], [16274, 17], [16275, 7], [16277, 17], [16278, 3], [16279, 18], [16280, 5], [16282, 19], [16284, 18], [16288, 4], [16289, 16], [16297, 16], [16298, 3], [16302, 7], [16303, 1], [16306, 12], [16307, 8], [16313, 3], [16315, 7], [16316, 1], [16320, 3], [16325, 12], [16326, 16], [16329, 9], [16335, 15], [16340, 2], [16345, 10], [16349, 9], [16352, 1], [16353, 7], [16361, 7], [16363, 5], [16364, 2], [16366, 11], [16369, 12], [16372, 19], [16376, 9], [16377, 6], [16380, 10], [16381, 18], [16383, 19], [16384, 14], [16385, 14], [16387, 6], [16391, 19], [16392, 4], [16396, 1], [16400, 18], [16405, 12], [16408, 5], [16413, 14], [16415, 2], [16416, 12], [16419, 17], [16421, 3], [16426, 20], [16434, 10], [16435, 20], [16437, 13], [16439, 8], [16449, 19], [16456, 9], [16457, 10], [16460, 20], [16461, 9], [16462, 10], [16466, 5], [16468, 11], [16473, 15], [16487, 16], [16489, 10], [16490, 20], [16494, 20], [16495, 13], [16500, 19], [16505, 3], [16506, 1], [16507, 17], [16512, 11], [16513, 6], [16515, 17], [16517, 12], [16518, 11], [16519, 19], [16521, 18], [16523, 5], [16524, 7], [16527, 19], [16530, 19], [16540, 19], [16544, 7], [16548, 12], [16551, 4], [16557, 11], [16562, 1], [16565, 1], [16570, 20], [16571, 13], [16573, 17], [16575, 13], [16577, 19], [16578, 16], [16579, 6], [16580, 13], [16587, 5], [16590, 13], [16591, 14], [16592, 4], [16593, 7], [16594, 14], [16601, 11], [16604, 1], [16605, 6], [16607, 19], [16616, 19], [16618, 20], [16621, 13], [16623, 8], [16624, 6], [16625, 5], [16626, 12], [16627, 15], [16629, 13], [16634, 4], [16635, 10], [16637, 7], [16639, 20], [16641, 3], [16644, 18], [16646, 9], [16648, 4], [16650, 3], [16653, 9], [16654, 17], [16656, 11], [16663, 5], [16664, 2], [16667, 17], [16670, 8], [16671, 8], [16681, 17], [16691, 19], [16692, 5], [16693, 15], [16709, 15], [16710, 5], [16711, 2], [16719, 12], [16720, 13], [16721, 2], [16724, 3], [16726, 6], [16728, 18], [16729, 19], [16731, 8], [16732, 2], [16742, 20], [16745, 17], [16747, 19], [16748, 17], [16749, 4], [16752, 5], [16756, 7], [16760, 2], [16761, 15], [16762, 20], [16766, 19], [16769, 7], [16770, 4], [16775, 19], [16776, 17], [16777, 9], [16778, 13], [16781, 18], [16784, 19], [16791, 3], [16792, 18], [16793, 5], [16795, 5], [16796, 7], [16799, 10], [16800, 11], [16810, 17], [16811, 20], [16817, 18], [16820, 15], [16828, 17], [16832, 6], [16833, 12], [16835, 19], [16840, 5], [16841, 6], [16844, 18], [16848, 19], [16852, 16], [16854, 19], [16858, 10], [16859, 17], [16864, 15], [16869, 5], [16870, 4], [16873, 3], [16874, 7], [16876, 5], [16878, 11], [16881, 12], [16885, 18], [16892, 14], [16895, 15], [16896, 19], [16898, 17], [16900, 3], [16907, 17], [16910, 2], [16913, 4], [16915, 8], [16916, 17], [16920, 6], [16921, 7], [16922, 8], [16926, 9], [16927, 19], [16928, 15], [16931, 11], [16933, 19], [16934, 18], [16940, 10], [16941, 18], [16944, 14], [16947, 10], [16948, 11], [16949, 17], [16952, 10], [16953, 12], [16954, 5], [16961, 9], [16964, 14], [16965, 11], [16966, 4], [16967, 6], [16970, 16], [16972, 13], [16974, 6], [16975, 9], [16976, 2], [16977, 17], [16979, 10], [16981, 8], [16985, 5], [16986, 3], [16988, 19], [16990, 1], [16992, 3], [17001, 10], [17004, 8], [17005, 8], [17008, 5], [17010, 7], [17016, 15], [17018, 18], [17020, 9], [17021, 12], [17030, 11], [17034, 4], [17041, 11], [17044, 20], [17045, 11], [17047, 2], [17048, 19], [17049, 9], [17053, 2], [17058, 6], [17059, 7], [17061, 4], [17063, 1], [17065, 12], [17068, 19], [17069, 19], [17070, 5], [17074, 18], [17079, 1], [17082, 9], [17086, 5], [17087, 16], [17093, 8], [17094, 16], [17095, 11], [17097, 11], [17099, 11], [17100, 15], [17101, 18], [17102, 11], [17104, 9], [17105, 18], [17107, 17], [17108, 2], [17110, 16], [17115, 1], [17116, 14], [17118, 4], [17120, 7], [17121, 9], [17124, 17], [17125, 9], [17130, 12], [17131, 19], [17132, 3], [17138, 19], [17139, 6], [17140, 8], [17155, 10], [17158, 3], [17160, 12], [17162, 13], [17165, 18], [17166, 15], [17169, 8], [17177, 14], [17183, 4], [17185, 4], [17186, 19], [17188, 18], [17189, 6], [17192, 17], [17193, 18], [17195, 3], [17196, 19], [17203, 12], [17206, 6], [17207, 17], [17209, 3], [17213, 19], [17215, 13], [17219, 11], [17222, 19], [17224, 8], [17227, 7], [17229, 8], [17235, 12], [17244, 12], [17245, 13], [17246, 2], [17247, 20], [17248, 5], [17250, 7], [17253, 6], [17257, 12], [17258, 5], [17259, 2], [17261, 6], [17263, 7], [17264, 16], [17265, 5], [17269, 12], [17273, 10], [17274, 19], [17281, 17], [17283, 8], [17288, 20], [17290, 4], [17298, 10], [17300, 2], [17301, 2], [17302, 19], [17304, 1], [17307, 18], [17310, 12], [17315, 17], [17320, 16], [17323, 18], [17325, 17], [17330, 1], [17333, 7], [17334, 10], [17336, 6], [17344, 18], [17345, 19], [17352, 13], [17354, 16], [17356, 6], [17357, 14], [17358, 9], [17360, 4], [17361, 12], [17366, 6], [17367, 6], [17368, 16], [17369, 9], [17370, 5], [17372, 18], [17377, 14], [17380, 7], [17384, 20], [17388, 3], [17389, 2], [17390, 8], [17392, 20], [17395, 2], [17396, 2], [17397, 20], [17401, 15], [17402, 17], [17408, 3], [17411, 8], [17419, 10], [17421, 9], [17425, 7], [17426, 14], [17432, 13], [17437, 4], [17441, 14], [17445, 11], [17448, 18], [17453, 20], [17456, 1], [17462, 18], [17466, 12], [17467, 17], [17469, 15], [17471, 1], [17479, 17], [17484, 7], [17487, 6], [17490, 20], [17491, 20], [17494, 19], [17497, 17], [17501, 9], [17506, 7], [17508, 19], [17509, 10], [17511, 1], [17516, 5], [17517, 13], [17524, 20], [17531, 11], [17532, 9], [17537, 6], [17539, 20], [17542, 5], [17547, 19], [17553, 11], [17556, 7], [17560, 5], [17564, 13], [17566, 6], [17570, 7], [17573, 16], [17574, 17], [17579, 17], [17581, 9], [17582, 2], [17584, 17], [17586, 3], [17587, 5], [17589, 13], [17593, 12], [17597, 9], [17600, 7], [17602, 7], [17604, 12], [17607, 9], [17611, 5], [17613, 12], [17614, 14], [17616, 17], [17619, 19], [17621, 5], [17628, 4], [17633, 11], [17634, 4], [17635, 6], [17646, 17], [17651, 11], [17652, 7], [17662, 14], [17664, 10], [17665, 8], [17670, 16], [17671, 9], [17675, 18], [17676, 9], [17677, 17], [17680, 16], [17686, 4], [17687, 4], [17688, 13], [17691, 5], [17693, 11], [17695, 2], [17697, 11], [17700, 11], [17706, 4], [17707, 17], [17709, 16], [17710, 1], [17715, 6], [17716, 17], [17717, 14], [17719, 4], [17720, 3], [17721, 19], [17722, 4], [17730, 15], [17732, 17], [17737, 7], [17738, 4], [17739, 10], [17743, 20], [17744, 4], [17745, 5], [17747, 13], [17748, 12], [17749, 15], [17752, 15], [17755, 10], [17757, 20], [17759, 14], [17763, 13], [17769, 12], [17771, 3], [17772, 3], [17775, 8], [17779, 12], [17781, 11], [17783, 4], [17790, 13], [17791, 8], [17792, 20], [17796, 9], [17799, 11], [17801, 1], [17803, 5], [17804, 19], [17808, 18], [17813, 8], [17815, 19], [17816, 6], [17819, 12], [17820, 19], [17821, 14], [17823, 4], [17824, 16], [17828, 19], [17830, 5], [17833, 11], [17839, 4], [17843, 14], [17848, 10], [17849, 6], [17850, 19], [17852, 6], [17853, 19], [17862, 18], [17863, 5], [17865, 16], [17871, 3], [17873, 7], [17874, 9], [17875, 7], [17877, 4], [17882, 20], [17885, 1], [17891, 11], [17893, 7], [17896, 5], [17899, 9], [17901, 11], [17903, 19], [17909, 10], [17910, 16], [17915, 10], [17917, 8], [17919, 17], [17924, 20], [17925, 7], [17928, 17], [17931, 17], [17935, 19], [17940, 17], [17941, 20], [17942, 18], [17947, 11], [17948, 16], [17949, 6], [17950, 2], [17953, 16], [17969, 16], [17978, 18], [17979, 10], [17980, 18], [17982, 1], [17984, 2], [17985, 11], [17989, 14], [17992, 12], [17994, 15], [17995, 10], [17998, 16], [18003, 11], [18004, 17], [18006, 12], [18011, 7], [18012, 11], [18013, 20], [18014, 5], [18017, 19], [18019, 9], [18021, 15], [18023, 6], [18025, 18], [18027, 2], [18029, 14], [18030, 16], [18032, 3], [18037, 8], [18038, 19], [18039, 5], [18041, 3], [18042, 3], [18043, 7], [18047, 8], [18049, 17], [18051, 18], [18052, 4], [18058, 12], [18059, 14], [18060, 12], [18064, 5], [18068, 11], [18069, 4], [18073, 16], [18074, 2], [18078, 19], [18081, 18], [18082, 16], [18085, 17], [18094, 7], [18098, 7], [18099, 7], [18102, 18], [18103, 1], [18107, 15], [18112, 6], [18115, 17], [18117, 18], [18123, 1], [18125, 4], [18126, 19], [18130, 18], [18132, 8], [18137, 13], [18139, 19], [18140, 7], [18142, 19], [18146, 12], [18148, 8], [18151, 10], [18156, 9], [18160, 1], [18161, 11], [18162, 4], [18163, 8], [18164, 12], [18167, 11], [18168, 1], [18171, 17], [18176, 3], [18179, 4], [18180, 14], [18182, 1], [18184, 8], [18185, 2], [18190, 15], [18191, 4], [18195, 16], [18196, 12], [18204, 15], [18205, 13], [18207, 1], [18211, 6], [18213, 8], [18215, 10], [18216, 10], [18220, 9], [18224, 15], [18229, 1], [18231, 10], [18232, 14], [18236, 4], [18239, 18], [18249, 4], [18250, 7], [18255, 10], [18258, 8], [18259, 11], [18271, 17], [18272, 18], [18278, 1], [18282, 3], [18284, 20], [18285, 10], [18288, 4], [18290, 1], [18292, 15], [18295, 3], [18296, 2], [18297, 11], [18300, 17], [18305, 5], [18306, 2], [18307, 17], [18308, 2], [18309, 5], [18319, 2], [18322, 7], [18329, 9], [18330, 7], [18331, 10], [18334, 15], [18336, 12], [18339, 11], [18344, 17], [18345, 19], [18346, 6], [18347, 17], [18353, 18], [18358, 2], [18359, 15], [18364, 8], [18369, 15], [18370, 4], [18373, 11], [18374, 12], [18375, 18], [18379, 11], [18382, 19], [18386, 6], [18388, 11], [18392, 17], [18397, 15], [18398, 14], [18399, 1], [18404, 12], [18409, 4], [18413, 9], [18414, 19], [18420, 7], [18424, 5], [18426, 9], [18428, 12], [18431, 11], [18436, 5], [18437, 10], [18439, 6], [18440, 9], [18441, 11], [18442, 5], [18448, 7], [18454, 18], [18455, 11], [18457, 3], [18458, 1], [18459, 13], [18462, 5], [18466, 16], [18472, 11], [18473, 16], [18474, 6], [18475, 11], [18478, 15], [18479, 16], [18480, 11], [18481, 16], [18489, 5], [18492, 16], [18493, 8], [18494, 16], [18500, 5], [18510, 12], [18516, 18], [18520, 14], [18522, 20], [18532, 19], [18533, 1], [18535, 17], [18536, 2], [18540, 1], [18542, 13], [18543, 8], [18545, 2], [18546, 13], [18549, 12], [18550, 2], [18551, 15], [18554, 15], [18557, 8], [18558, 19], [18565, 12], [18579, 11], [18581, 5], [18582, 3], [18591, 2], [18594, 2], [18595, 18], [18601, 19], [18603, 17], [18619, 14], [18620, 3], [18621, 6], [18626, 2], [18632, 11], [18635, 9], [18638, 13], [18639, 13], [18640, 10], [18642, 18], [18643, 18], [18646, 14], [18647, 4], [18653, 15], [18657, 6], [18659, 10], [18662, 3], [18663, 6], [18665, 16], [18669, 1], [18672, 5], [18674, 8], [18675, 16], [18677, 6], [18680, 19], [18690, 19], [18697, 9], [18698, 19], [18699, 8], [18700, 4], [18702, 10], [18706, 13], [18711, 6], [18712, 11], [18714, 13], [18716, 13], [18718, 6], [18721, 16], [18723, 16], [18726, 7], [18727, 6], [18728, 4], [18730, 14], [18735, 2], [18742, 5], [18748, 18], [18755, 1], [18758, 17], [18761, 9], [18768, 1], [18773, 8], [18776, 5], [18777, 7], [18784, 19], [18785, 8], [18789, 10], [18791, 18], [18793, 2], [18794, 11], [18797, 13], [18799, 4], [18800, 9], [18803, 5], [18804, 8], [18807, 15], [18811, 19], [18816, 16], [18817, 19], [18818, 14], [18819, 2], [18820, 4], [18822, 17], [18824, 16], [18826, 19], [18827, 1], [18828, 2], [18831, 9], [18833, 20], [18835, 15], [18837, 6], [18841, 4], [18843, 14], [18846, 10], [18850, 3], [18851, 2], [18852, 7], [18856, 6], [18859, 18], [18860, 15], [18861, 8], [18862, 19], [18876, 7], [18881, 19], [18882, 4], [18885, 16], [18886, 17], [18887, 3], [18888, 2], [18889, 14], [18890, 17], [18891, 16], [18892, 19], [18897, 15], [18901, 10], [18903, 4], [18904, 15], [18907, 6], [18911, 10], [18914, 9], [18918, 10], [18921, 18], [18925, 16], [18928, 5], [18929, 7], [18933, 20], [18945, 1], [18947, 7], [18948, 17], [18954, 16], [18957, 12], [18959, 17], [18960, 10], [18962, 11], [18964, 18], [18968, 5], [18971, 13], [18976, 20], [18979, 16], [18980, 18], [18983, 16], [18986, 18], [18991, 9], [18993, 14], [18994, 19], [18997, 18], [18999, 12], [19000, 18], [19001, 3], [19002, 10], [19012, 13], [19013, 6], [19016, 19], [19017, 19], [19020, 11], [19021, 4], [19023, 11], [19027, 19], [19028, 6], [19035, 19], [19036, 18], [19039, 2], [19043, 19], [19045, 7], [19047, 19], [19050, 3], [19054, 11], [19058, 5], [19062, 20], [19064, 5], [19067, 11], [19069, 19], [19071, 4], [19074, 12], [19077, 2], [19082, 11], [19088, 15], [19091, 16], [19093, 11], [19095, 5], [19097, 17], [19105, 2], [19108, 8], [19110, 5], [19112, 18], [19113, 7], [19114, 19], [19121, 1], [19122, 10], [19124, 1], [19125, 14], [19126, 2], [19130, 6], [19133, 3], [19134, 16], [19136, 10], [19138, 11], [19139, 11], [19142, 7], [19149, 1], [19153, 16], [19158, 10], [19161, 17], [19165, 2], [19168, 14], [19173, 6], [19174, 9], [19178, 9], [19179, 2], [19180, 19], [19181, 2], [19182, 15], [19184, 19], [19187, 2], [19189, 7], [19190, 8], [19196, 10], [19202, 8], [19205, 1], [19207, 5], [19208, 10], [19209, 19], [19218, 9], [19221, 2], [19223, 3], [19224, 17], [19225, 4], [19226, 16], [19230, 15], [19231, 20], [19232, 19], [19233, 12], [19238, 20], [19242, 11], [19246, 5], [19247, 17], [19248, 19], [19250, 17], [19251, 9], [19261, 13], [19262, 9], [19266, 4], [19276, 14], [19279, 18], [19280, 5], [19292, 8], [19295, 18], [19296, 11], [19299, 5], [19303, 13], [19305, 19], [19309, 9], [19310, 18], [19314, 17], [19315, 19], [19320, 16], [19322, 6], [19329, 4], [19338, 19], [19347, 4], [19348, 3], [19350, 2], [19356, 20], [19361, 3], [19362, 17], [19367, 2], [19373, 1], [19376, 7], [19382, 19], [19386, 2], [19388, 6], [19393, 15], [19394, 18], [19397, 3], [19398, 9], [19400, 15], [19407, 18], [19408, 18], [19412, 9], [19417, 20], [19419, 5], [19420, 7], [19421, 19], [19428, 15], [19429, 18], [19430, 1], [19437, 3], [19443, 16], [19448, 5], [19451, 7], [19454, 6], [19458, 4], [19461, 19], [19467, 17], [19468, 17], [19469, 14], [19470, 17], [19475, 3], [19478, 7], [19479, 11], [19480, 11], [19481, 2], [19485, 19], [19486, 3], [19487, 10], [19497, 20], [19499, 11], [19500, 17], [19501, 12], [19502, 19], [19503, 17], [19504, 19], [19505, 5], [19506, 15], [19509, 5], [19511, 15], [19512, 4], [19513, 4], [19518, 3], [19520, 16], [19523, 8], [19525, 4], [19529, 8], [19531, 5], [19532, 17], [19533, 2], [19535, 4], [19539, 13], [19540, 5], [19545, 18], [19546, 9], [19551, 4], [19554, 3], [19556, 4], [19557, 5], [19559, 6], [19563, 19], [19567, 4], [19568, 3], [19569, 15], [19573, 6], [19576, 8], [19581, 3], [19584, 3], [19585, 5], [19587, 4], [19588, 13], [19600, 19], [19601, 3], [19603, 4], [19605, 3], [19607, 17], [19608, 20], [19609, 2], [19612, 8], [19618, 16], [19619, 4], [19621, 5], [19622, 3], [19623, 16], [19624, 5], [19625, 6], [19628, 4], [19631, 15], [19632, 1], [19633, 8], [19634, 8], [19637, 20], [19638, 19], [19645, 16], [19646, 11], [19648, 11], [19651, 11], [19653, 9], [19655, 6], [19663, 16], [19669, 13], [19672, 20], [19673, 14], [19674, 16], [19681, 12], [19682, 10], [19683, 6], [19684, 20], [19686, 4], [19688, 10], [19689, 6], [19690, 5], [19691, 4], [19693, 19], [19694, 9], [19696, 14], [19698, 12], [19700, 6], [19702, 1], [19703, 16], [19706, 2], [19709, 20], [19710, 14], [19712, 6], [19715, 10], [19717, 20], [19723, 19], [19729, 18], [19732, 9], [19733, 17], [19737, 15], [19739, 6], [19740, 14], [19742, 1], [19744, 8], [19746, 18], [19752, 9], [19756, 12], [19759, 17], [19760, 12], [19762, 5], [19763, 3], [19765, 15], [19766, 16], [19767, 15], [19768, 6], [19774, 4], [19779, 20], [19783, 2], [19785, 18], [19787, 8], [19789, 15], [19790, 7], [19794, 7], [19801, 4], [19802, 17], [19805, 13], [19806, 9], [19808, 19], [19812, 2], [19820, 5], [19834, 16], [19836, 5], [19837, 18], [19838, 19], [19839, 19], [19841, 20], [19847, 4], [19850, 11], [19853, 18], [19854, 6], [19858, 3], [19860, 7], [19864, 9], [19865, 8], [19867, 6], [19870, 2], [19875, 1], [19878, 16], [19884, 15], [19886, 18], [19888, 20], [19889, 7], [19891, 10], [19895, 18], [19897, 5], [19899, 7], [19900, 12], [19902, 14], [19909, 1], [19918, 18], [19920, 11], [19921, 6], [19925, 10], [19936, 11], [19939, 16], [19941, 13], [19942, 18], [19948, 7], [19950, 16], [19958, 19], [19959, 19], [19960, 5], [19961, 3], [19965, 8], [19971, 13], [19972, 11], [19973, 3], [19974, 2], [19980, 20], [19981, 11], [19982, 2], [19990, 5], [19991, 10], [19992, 15], [19996, 5], [19997, 4], [19998, 8], [19999, 20], [20001, 10], [20003, 8], [20006, 3], [20014, 6], [20015, 20], [20017, 4], [20018, 12], [20019, 19], [20022, 4], [20025, 15], [20031, 12], [20032, 17], [20036, 15], [20037, 13], [20045, 5], [20046, 18], [20049, 17], [20054, 3], [20055, 15], [20060, 17], [20063, 15], [20064, 8], [20068, 10], [20070, 5], [20079, 8], [20081, 6], [20082, 6], [20083, 18], [20085, 8], [20087, 5], [20093, 1], [20095, 10], [20099, 1], [20105, 4], [20107, 7], [20108, 2], [20109, 19], [20110, 16], [20111, 13], [20113, 10], [20114, 18], [20115, 17], [20118, 6], [20119, 4], [20120, 8], [20122, 10], [20125, 11], [20127, 6], [20128, 16], [20132, 8], [20133, 18], [20134, 3], [20136, 3], [20139, 1], [20140, 13], [20144, 10], [20145, 9], [20149, 10], [20152, 13], [20153, 4], [20154, 2], [20155, 2], [20158, 13], [20161, 12], [20162, 1], [20168, 10], [20174, 17], [20183, 13], [20185, 2], [20189, 14], [20190, 7], [20191, 19], [20195, 7], [20196, 7], [20198, 8], [20202, 19], [20206, 18], [20207, 19], [20213, 8], [20214, 13], [20216, 10], [20218, 18], [20226, 5], [20228, 10], [20233, 1], [20234, 11], [20240, 5], [20242, 11], [20246, 5], [20248, 6], [20249, 11], [20250, 13], [20252, 13], [20253, 16], [20254, 15], [20259, 7], [20261, 17], [20264, 10], [20265, 19], [20268, 4], [20269, 20], [20270, 14], [20272, 1], [20274, 14], [20276, 15], [20285, 5], [20286, 5], [20290, 16], [20292, 7], [20293, 6], [20294, 2], [20296, 19], [20297, 11], [20304, 9], [20309, 7], [20310, 6], [20316, 14], [20319, 7], [20320, 7], [20323, 11], [20324, 12], [20329, 7], [20331, 17], [20332, 19], [20333, 1], [20334, 5], [20340, 17], [20341, 12], [20342, 3], [20344, 16], [20345, 20], [20346, 17], [20348, 2], [20353, 20], [20355, 15], [20360, 14], [20361, 10], [20362, 15], [20366, 19], [20368, 19], [20372, 14], [20376, 5], [20389, 9], [20396, 2], [20399, 16], [20402, 7], [20409, 18], [20411, 4], [20417, 18], [20421, 17], [20423, 13], [20426, 14], [20427, 20], [20428, 10], [20438, 11], [20443, 12], [20444, 10], [20445, 11], [20446, 4], [20447, 8], [20448, 9], [20449, 19], [20450, 3], [20451, 20], [20452, 8], [20454, 14], [20459, 17], [20461, 6], [20463, 10], [20464, 4], [20465, 9], [20466, 2], [20470, 18], [20472, 18], [20476, 2], [20478, 8], [20481, 4], [20486, 7], [20491, 17], [20496, 18], [20499, 11], [20509, 1], [20510, 3], [20514, 15], [20516, 6], [20518, 18], [20519, 11], [20520, 18], [20522, 19], [20523, 20], [20524, 13], [20528, 18], [20531, 12], [20533, 11], [20545, 1], [20548, 17], [20550, 3], [20551, 2], [20554, 2], [20556, 13], [20561, 5], [20567, 9], [20570, 15], [20575, 18], [20577, 1], [20579, 7], [20585, 20], [20587, 11], [20589, 19], [20590, 2], [20594, 5], [20595, 6], [20596, 7], [20601, 2], [20602, 1], [20603, 3], [20606, 19], [20608, 17], [20609, 18], [20614, 14], [20615, 20], [20616, 17], [20617, 18], [20618, 17], [20620, 6], [20621, 4], [20623, 12], [20624, 1], [20627, 6], [20628, 17], [20629, 2], [20630, 19], [20633, 9], [20634, 14], [20637, 14], [20640, 1], [20641, 7], [20643, 20], [20645, 6], [20646, 11], [20653, 11], [20654, 1], [20655, 14], [20656, 8], [20657, 8], [20662, 18], [20665, 1], [20667, 10], [20669, 12], [20670, 2], [20672, 18], [20673, 19], [20678, 19], [20687, 7], [20688, 18], [20691, 20], [20693, 4], [20699, 14], [20701, 3], [20705, 6], [20706, 5], [20707, 16], [20708, 15], [20709, 10], [20711, 15], [20714, 9], [20715, 16], [20720, 20], [20722, 12], [20723, 14], [20725, 1], [20731, 10], [20739, 5], [20741, 2], [20742, 14], [20751, 3], [20762, 19], [20763, 10], [20765, 4], [20767, 16], [20771, 10], [20778, 16], [20783, 9], [20784, 16], [20787, 8], [20789, 9], [20792, 1], [20797, 6], [20801, 16], [20802, 8], [20803, 20], [20810, 19], [20812, 19], [20816, 6], [20822, 11], [20826, 1], [20827, 14], [20829, 20], [20831, 17], [20841, 5], [20845, 17], [20848, 4], [20853, 4], [20855, 6], [20857, 11], [20861, 17], [20862, 5], [20864, 15], [20865, 19], [20866, 1], [20868, 15], [20870, 16], [20872, 18], [20873, 12], [20878, 4], [20880, 4], [20886, 9], [20887, 11], [20888, 19], [20889, 1], [20891, 12], [20893, 5], [20898, 1], [20899, 19], [20901, 13], [20906, 11], [20907, 1], [20908, 5], [20911, 11], [20914, 8], [20915, 1], [20916, 3], [20919, 2], [20922, 20], [20924, 19], [20928, 4], [20934, 10], [20943, 11], [20946, 19], [20950, 10], [20951, 12], [20952, 2], [20953, 9], [20954, 19], [20966, 5], [20968, 17], [20972, 17], [20973, 17], [20975, 12], [20981, 19], [20983, 19], [20985, 13], [20988, 6], [20989, 6], [20990, 18], [20991, 10], [20992, 17], [20993, 12], [20996, 8], [20997, 19], [20998, 9], [20999, 10], [21000, 2], [21002, 3], [21010, 9], [21013, 9], [21017, 7], [21018, 18], [21019, 2], [21023, 7], [21035, 9], [21038, 17], [21047, 16], [21055, 13], [21061, 12], [21063, 17], [21068, 11], [21073, 18], [21078, 9], [21079, 15], [21080, 14], [21081, 13], [21096, 12], [21097, 18], [21098, 18], [21103, 1], [21104, 18], [21106, 9], [21109, 3], [21111, 19], [21114, 6], [21120, 5], [21122, 2], [21123, 19], [21125, 4], [21126, 17], [21127, 12], [21128, 16], [21130, 10], [21132, 9], [21133, 3], [21134, 18], [21137, 2], [21138, 12], [21139, 17], [21140, 8], [21145, 19], [21147, 3], [21148, 14], [21151, 10], [21153, 2], [21154, 17], [21156, 10], [21163, 12], [21165, 14], [21166, 15], [21168, 18], [21178, 4], [21180, 12], [21188, 5], [21189, 18], [21190, 9], [21191, 20], [21192, 20], [21193, 9], [21196, 12], [21202, 6], [21203, 18], [21204, 9], [21209, 7], [21210, 12], [21211, 1], [21212, 7], [21213, 8], [21214, 10], [21215, 13], [21221, 18], [21222, 1], [21223, 13], [21224, 10], [21226, 11], [21232, 2], [21234, 7], [21236, 9], [21238, 9], [21241, 20], [21252, 18], [21255, 4], [21257, 18], [21259, 9], [21263, 12], [21264, 3], [21265, 1], [21267, 2], [21268, 19], [21269, 18], [21273, 7], [21279, 19], [21288, 13], [21297, 15], [21300, 15], [21302, 7], [21304, 11], [21308, 18], [21312, 15], [21314, 1], [21315, 5], [21317, 19], [21319, 10], [21321, 18], [21323, 12], [21329, 11], [21331, 12], [21333, 5], [21336, 5], [21338, 10], [21340, 5], [21342, 6], [21345, 11], [21346, 4], [21347, 15], [21354, 19], [21361, 19], [21362, 5], [21365, 8], [21366, 18], [21368, 8], [21369, 17], [21371, 9], [21377, 17], [21379, 5], [21384, 15], [21385, 15], [21386, 20], [21393, 10], [21397, 7], [21398, 16], [21404, 3], [21405, 8], [21409, 8], [21410, 14], [21413, 7], [21422, 6], [21424, 4], [21426, 9], [21427, 18], [21428, 15], [21429, 6], [21430, 19], [21432, 5], [21439, 6], [21441, 11], [21447, 14], [21449, 4], [21451, 15], [21453, 6], [21454, 10], [21457, 13], [21459, 3], [21465, 5], [21470, 17], [21472, 6], [21474, 2], [21477, 7], [21484, 9], [21487, 14], [21489, 3], [21491, 1], [21496, 7], [21502, 17], [21505, 20], [21509, 5], [21514, 20], [21515, 14], [21521, 14], [21522, 6], [21524, 19], [21525, 4], [21530, 3], [21533, 10], [21538, 18], [21542, 1], [21546, 18], [21547, 6], [21548, 19], [21552, 18], [21554, 20], [21564, 12], [21565, 8], [21569, 9], [21571, 9], [21577, 18], [21583, 10], [21585, 9], [21591, 8], [21592, 15], [21593, 13], [21594, 17], [21595, 6], [21602, 2], [21603, 10], [21605, 8], [21606, 11], [21607, 9], [21610, 9], [21614, 19], [21620, 10], [21621, 20], [21623, 13], [21625, 14], [21626, 2], [21627, 3], [21630, 6], [21634, 18], [21636, 8], [21637, 8], [21639, 3], [21641, 8], [21642, 10], [21644, 13], [21646, 8], [21661, 1], [21665, 4], [21666, 4], [21668, 5], [21675, 14], [21678, 20], [21679, 20], [21682, 11], [21687, 18], [21688, 9], [21691, 10], [21695, 19], [21696, 9], [21697, 9], [21698, 11], [21700, 5], [21707, 2], [21717, 5], [21718, 7], [21720, 16], [21721, 7], [21722, 20], [21723, 16], [21724, 11], [21727, 15], [21730, 7], [21735, 1], [21736, 18], [21737, 3], [21738, 11], [21742, 15], [21744, 17], [21747, 1], [21749, 6], [21753, 9], [21754, 5], [21755, 9], [21756, 2], [21757, 9], [21759, 2], [21760, 6], [21764, 18], [21765, 3], [21766, 5], [21767, 11], [21769, 7], [21771, 19], [21774, 2], [21775, 8], [21777, 17], [21778, 7], [21780, 12], [21781, 9], [21784, 2], [21791, 15], [21793, 17], [21796, 5], [21801, 20], [21803, 5], [21806, 17], [21809, 2], [21811, 19], [21813, 1], [21815, 17], [21816, 10], [21817, 5], [21819, 2], [21822, 15], [21824, 20], [21826, 7], [21827, 12], [21830, 9], [21833, 14], [21834, 4], [21835, 17], [21836, 14], [21840, 1], [21843, 16], [21845, 4], [21847, 3], [21850, 10], [21851, 8], [21852, 10], [21854, 19], [21855, 12], [21857, 1], [21858, 7], [21859, 11], [21864, 7], [21869, 11], [21873, 16], [21874, 17], [21875, 10], [21876, 11], [21881, 18], [21883, 16], [21884, 2], [21887, 18], [21891, 18], [21897, 5], [21901, 20], [21906, 2], [21911, 12], [21912, 17], [21913, 12], [21916, 20], [21922, 17], [21925, 5], [21928, 11], [21931, 18], [21938, 10], [21939, 19], [21941, 14], [21942, 2], [21945, 18], [21948, 5], [21954, 8], [21959, 4], [21961, 16], [21964, 5], [21969, 13], [21979, 8], [21981, 20], [21983, 9], [21984, 16], [21985, 17], [21986, 13], [21989, 18], [21990, 5], [21993, 13], [21994, 7], [21998, 9], [21999, 19], [22000, 10], [22002, 10], [22005, 3], [22006, 10], [22010, 20], [22011, 14], [22012, 11], [22015, 7], [22018, 9], [22026, 11], [22033, 10], [22036, 8], [22037, 1], [22040, 17], [22041, 12], [22043, 5], [22045, 1], [22047, 1], [22048, 12], [22049, 11], [22050, 3], [22051, 4], [22055, 6], [22057, 17], [22061, 3], [22062, 5], [22067, 13], [22068, 16], [22069, 2], [22072, 13], [22076, 16], [22077, 7], [22079, 11], [22080, 7], [22082, 4], [22083, 4], [22086, 1], [22089, 5], [22090, 13], [22098, 2], [22100, 13], [22102, 3], [22103, 6], [22107, 10], [22108, 15], [22111, 10], [22114, 12], [22117, 5], [22118, 13], [22119, 2], [22120, 6], [22122, 2], [22125, 4], [22128, 5], [22131, 18], [22132, 18], [22135, 9], [22138, 20], [22139, 9], [22142, 17], [22144, 1], [22147, 7], [22149, 4], [22151, 3], [22153, 19], [22160, 2], [22161, 10], [22166, 2], [22167, 6], [22169, 16], [22175, 19], [22178, 12], [22180, 6], [22181, 20], [22182, 16], [22186, 19], [22188, 20], [22189, 5], [22190, 12], [22195, 10], [22196, 13], [22201, 9], [22205, 11], [22207, 10], [22209, 2], [22213, 7], [22215, 1], [22217, 3], [22218, 1], [22223, 14], [22224, 11], [22225, 12], [22228, 4], [22229, 19], [22233, 4], [22234, 8], [22235, 14], [22239, 11], [22246, 10], [22247, 11], [22255, 8], [22256, 8], [22260, 11], [22261, 10], [22262, 6], [22270, 9], [22271, 11], [22276, 15], [22277, 6], [22278, 19], [22280, 19], [22282, 5], [22285, 16], [22287, 5], [22289, 15], [22299, 11], [22310, 19], [22311, 5], [22315, 20], [22317, 1], [22318, 14], [22323, 19], [22327, 16], [22328, 12], [22330, 8], [22337, 12], [22341, 1], [22348, 11], [22350, 17], [22351, 10], [22353, 9], [22354, 15], [22355, 20], [22356, 19], [22357, 5], [22358, 8], [22359, 9], [22367, 19], [22372, 5], [22374, 18], [22377, 16], [22380, 11], [22382, 9], [22384, 7], [22385, 4], [22387, 3], [22388, 12], [22395, 6], [22398, 9], [22400, 17], [22401, 8], [22403, 11], [22405, 13], [22408, 9], [22418, 11], [22422, 18], [22424, 2], [22427, 5], [22430, 8], [22431, 9], [22433, 17], [22434, 6], [22435, 3], [22446, 7], [22450, 9], [22451, 12], [22452, 2], [22453, 9], [22458, 7], [22461, 9], [22463, 9], [22465, 12], [22467, 4], [22468, 14], [22469, 6], [22470, 6], [22478, 8], [22479, 19], [22481, 8], [22486, 12], [22492, 12], [22495, 11], [22496, 7], [22499, 3], [22500, 3], [22501, 10], [22502, 8], [22505, 4], [22509, 15], [22510, 10], [22522, 1], [22524, 1], [22528, 19], [22530, 5], [22534, 12], [22536, 11], [22537, 12], [22538, 18], [22546, 4], [22547, 11], [22548, 14], [22552, 7], [22554, 11], [22556, 10], [22557, 5], [22559, 9], [22560, 19], [22562, 10], [22566, 3], [22567, 13], [22568, 3], [22569, 19], [22570, 14], [22578, 5], [22579, 4], [22581, 15], [22584, 17], [22585, 12], [22588, 8], [22591, 19], [22592, 1], [22594, 14], [22597, 5], [22598, 10], [22603, 12], [22605, 6], [22607, 20], [22608, 7], [22613, 4], [22618, 4], [22619, 1], [22624, 2], [22625, 1], [22629, 19], [22631, 10], [22633, 16], [22635, 4], [22638, 7], [22640, 10], [22641, 5], [22642, 10], [22643, 15], [22648, 9], [22652, 18], [22659, 13], [22660, 2], [22662, 9], [22665, 20], [22666, 8], [22667, 3], [22669, 18], [22672, 20], [22673, 7], [22675, 20], [22681, 3], [22685, 1], [22688, 10], [22690, 19], [22693, 11], [22696, 18], [22698, 9], [22701, 9], [22707, 20], [22709, 16], [22713, 8], [22717, 11], [22719, 17], [22721, 18], [22723, 4], [22728, 14], [22729, 11], [22732, 6], [22734, 9], [22741, 12], [22742, 17], [22744, 15], [22746, 14], [22750, 20], [22751, 11], [22752, 11], [22754, 3], [22760, 7], [22761, 7], [22764, 19], [22765, 10], [22766, 15], [22767, 13], [22768, 8], [22769, 14], [22775, 9], [22777, 16], [22779, 5], [22780, 2], [22782, 19], [22785, 13], [22786, 19], [22788, 7], [22790, 7], [22793, 13], [22795, 6], [22800, 8], [22803, 2], [22805, 18], [22810, 15], [22812, 4], [22815, 13], [22816, 16], [22818, 15], [22821, 6], [22822, 2], [22824, 19], [22826, 13], [22830, 4], [22833, 2], [22837, 8], [22839, 16], [22840, 6], [22841, 20], [22842, 4], [22847, 11], [22848, 20], [22853, 6], [22858, 11], [22863, 13], [22864, 5], [22868, 14], [22871, 10], [22872, 8], [22873, 19], [22874, 17], [22882, 17], [22883, 19], [22889, 17], [22890, 17], [22894, 3], [22898, 15], [22902, 10], [22903, 8], [22908, 15], [22912, 3], [22914, 2], [22916, 12], [22918, 5], [22919, 10], [22921, 8], [22922, 20], [22923, 13], [22925, 6], [22926, 5], [22930, 3], [22931, 3], [22933, 4], [22939, 13], [22941, 5], [22942, 17], [22943, 4], [22945, 6], [22948, 19], [22950, 9], [22958, 16], [22959, 18], [22962, 2], [22965, 18], [22966, 11], [22969, 17], [22971, 17], [22972, 9], [22975, 4], [22976, 11], [22977, 17], [22979, 18], [22981, 3], [22982, 16], [22983, 17], [22985, 9], [22986, 6], [22987, 5], [22988, 16], [22992, 1], [22993, 11], [22995, 14], [22997, 15], [23000, 1], [23008, 19], [23012, 10], [23015, 1], [23025, 13], [23026, 5], [23031, 13], [23032, 19], [23034, 4], [23036, 20], [23037, 8], [23038, 6], [23045, 11], [23049, 15], [23053, 19], [23059, 6], [23060, 10], [23062, 7], [23063, 20], [23065, 3], [23066, 4], [23068, 8], [23070, 18], [23072, 12], [23074, 1], [23075, 17], [23076, 19], [23077, 11], [23086, 14], [23087, 4], [23088, 1], [23090, 15], [23091, 5], [23092, 8], [23095, 13], [23096, 13], [23098, 11], [23101, 10], [23102, 10], [23106, 17], [23111, 10], [23112, 3], [23114, 9], [23124, 15], [23126, 6], [23127, 19], [23131, 13], [23133, 15], [23134, 7], [23135, 11], [23136, 12], [23138, 20], [23139, 20], [23142, 18], [23143, 16], [23152, 12], [23153, 14], [23156, 6], [23158, 17], [23159, 15], [23163, 20], [23167, 16], [23168, 17], [23169, 8], [23171, 11], [23174, 1], [23175, 2], [23177, 12], [23178, 6], [23187, 10], [23189, 19], [23194, 1], [23195, 11], [23196, 20], [23198, 18], [23199, 7], [23204, 19], [23209, 18], [23211, 14], [23216, 7], [23217, 20], [23218, 2], [23219, 4], [23220, 7], [23222, 18], [23225, 20], [23228, 5], [23231, 4], [23234, 5], [23235, 8], [23239, 11], [23244, 13], [23246, 11], [23247, 2], [23255, 8], [23256, 18], [23261, 7], [23265, 6], [23266, 5], [23276, 15], [23279, 4], [23282, 1], [23285, 5], [23286, 4], [23292, 1], [23294, 9], [23297, 19], [23300, 10], [23302, 10], [23304, 10], [23306, 5], [23307, 11], [23312, 18], [23315, 7], [23317, 1], [23319, 14], [23322, 12], [23323, 20], [23329, 1], [23331, 4], [23333, 18], [23336, 20], [23337, 6], [23339, 13], [23342, 6], [23344, 12], [23347, 15], [23349, 5], [23350, 18], [23354, 9], [23362, 1], [23363, 19], [23364, 15], [23367, 15], [23372, 13], [23375, 18], [23382, 16], [23389, 11], [23393, 6], [23396, 1], [23399, 5], [23401, 6], [23403, 19], [23406, 13], [23409, 5], [23414, 6], [23415, 15], [23416, 11], [23418, 16], [23422, 7], [23424, 19], [23426, 12], [23429, 16], [23436, 8], [23437, 7], [23442, 2], [23443, 20], [23444, 4], [23446, 8], [23448, 11], [23451, 2], [23456, 7], [23462, 20], [23465, 3], [23468, 2], [23470, 17], [23476, 20], [23477, 7], [23481, 3], [23484, 16], [23492, 17], [23497, 4], [23508, 6], [23512, 15], [23514, 10], [23515, 10], [23516, 2], [23524, 12], [23526, 16], [23528, 19], [23530, 9], [23533, 11], [23535, 17], [23545, 2], [23546, 3], [23553, 5], [23554, 1], [23555, 11], [23560, 10], [23563, 1], [23565, 7], [23569, 8], [23570, 14], [23572, 8], [23584, 1], [23585, 11], [23588, 11], [23591, 18], [23594, 10], [23600, 1], [23607, 1], [23613, 14], [23617, 8], [23621, 5], [23622, 19], [23623, 11], [23626, 4], [23627, 18], [23628, 18], [23629, 6], [23630, 2], [23631, 4], [23636, 4], [23637, 19], [23640, 7], [23642, 2], [23646, 10], [23648, 14], [23649, 11], [23650, 17], [23652, 16], [23653, 18], [23655, 5], [23657, 9], [23663, 14], [23665, 16], [23669, 17], [23673, 1], [23674, 5], [23678, 5], [23679, 10], [23680, 11], [23685, 18], [23687, 11], [23696, 5], [23697, 18], [23699, 11], [23700, 5], [23702, 2], [23703, 6], [23704, 9], [23706, 2], [23707, 9], [23708, 10], [23709, 20], [23710, 15], [23711, 14], [23713, 20], [23717, 4], [23718, 19], [23721, 15], [23726, 10], [23731, 19], [23739, 11], [23744, 19], [23745, 17], [23746, 3], [23748, 8], [23750, 12], [23752, 12], [23753, 6], [23759, 3], [23762, 6], [23765, 13], [23767, 5], [23771, 11], [23773, 5], [23774, 2], [23776, 10], [23779, 5], [23782, 5], [23783, 14], [23789, 7], [23792, 10], [23797, 8], [23809, 14], [23810, 4], [23813, 17], [23823, 6], [23825, 6], [23826, 17], [23829, 18], [23830, 10], [23831, 4], [23834, 2], [23837, 9], [23839, 17], [23840, 19], [23841, 7], [23843, 11], [23844, 6], [23846, 3], [23847, 9], [23848, 4], [23849, 7], [23851, 13], [23858, 20], [23859, 11], [23860, 3], [23864, 6], [23865, 3], [23870, 10], [23871, 3], [23875, 3], [23876, 2], [23888, 18], [23890, 3], [23891, 3], [23892, 17], [23893, 5], [23895, 19], [23898, 1], [23899, 18], [23901, 20], [23903, 2], [23906, 9], [23907, 8], [23908, 8], [23909, 13], [23911, 15], [23913, 19], [23915, 14], [23916, 5], [23917, 10], [23920, 2], [23922, 20], [23923, 11], [23924, 5], [23934, 5], [23935, 3], [23937, 5], [23938, 5], [23939, 20], [23940, 7], [23941, 7], [23944, 14], [23946, 1], [23949, 17], [23952, 7], [23954, 1], [23955, 13], [23956, 17], [23957, 12], [23960, 2], [23961, 6], [23962, 9], [23964, 9], [23966, 1], [23969, 20], [23971, 19], [23973, 11], [23976, 10], [23979, 4], [23983, 6], [23984, 17], [23986, 9], [23991, 12], [23992, 4], [23998, 5], [24000, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "brilliant-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write csv data in csv\n",
    "with open('test_labels_NN.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['id', 'class'])\n",
    "    writer.writerows(csv_data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
